MEET 1: 

 Não, não, não, não, acho que está no Discord, estava procurando meus files aqui, não achei. Eu te mudei copy paste no disco aqui, só quero saber como é que era. Pois é. Pois é, papo. Aqui, achei já. Mais baixo do que o esperado. Acrição com o message, tá, beleza, eu tenho aqui, eu vou copiar com o Laisso aqui no noxio para você se ver.

 E aí a gente pode começar a partir daí? Deixa eu dar uma atividade. Pede pra ele aí. Cara, se vocês quiserem já tipo colocar, eu sei que tá meio que escrito aí, mas assim, de bate pronto fácil, né? O que precisa ser feito é trabalhar numa aplicação de transcrição e legendagem. Esse é o ponto 1. Aí o ponto 2 é...
 e traduzir. Traduzir parada por outras línguas. Isso no final desse documento aí tem exatamente isso. As principais demandas ali. Aí eu tô... aí eu tô maior agora. Aí te vi louco o que é que eu organizado. Tu salvou? Ele jogou embaixo e veio de substituir. Ah, beleza. Eu vou apagar de cima então.
 O que maravilha, eu peguei o bagulho, você me copiou e colou no WhatsApp, e o bagulho virou um documento formatado. Mas isso é o Notion, não é? É, é o Notion. Mas aí ele faz para você? Faz, tem OER aqui dentro. Então, mas aí você precisa falar que você quer isso, ele já fala. Não, não, não, ele copiou e colou, apertei espaço aqui, eu falei, ah, formata para mim. Fodido, fodido. E é bom, vamos lá. Ele está usando o Emberscript hoje.
 Sim, né? A gente deu até uma olhada como é que era, achamos caríssimo inclusive, né? Isso, se eu não me engano, é 1,60 por minuto para um humano transcrever e 100% de precisão. E não sei quantos centavos de dólar também para um robô escrever com 85% de precisão. E aí, partindo disso, o que eu acho é que a gente consegue, com o experimento que a gente tem hoje, gerar uma transcrição com 100% de precisão.
 uns 95% de precisão para mais usando o AI. Isso diretaço. No sentido de que só botar na ferramenta para transcrever e colocar no padrão ali. Nem no padrão, só para pegar o que está falado. Por exemplo, agora mostra ali o que tu transcreveu, o Jeff, sabe? Eu fiz um teste, gerando isso aí, tem algumas coisas que ele... Aí no larga até pegou o certo...
 No minuto 1 ele fala como a gente não tem cut-ness. Ele fala isso. Como a gente não tem cut-ness, no modelo Small eu não consigo pegar essa frase. Legal. Aí ele já tem uns detalhes assim, mas o que eu tinha feito era pegar o que foi dito, a transcrição, colocada na AI para ela falar assim e perguntar para ela, e ela dar uma olhada baseada no contexto.
 pode vir uma coisa meio errada na transcrição, mas não acontece, não pega. E ela já fez uns ajustes legal, então com mais tempo de para ajustes a gente consegue deixar uns, sei lá, uns 98% para só o humano dar uma revisada no final. Isso partindo da transcrição. A partir de deixar para informatos de legenda é bem facinho. A gente já tem como deixar nesse formato aí que tá meio tosco ainda de só dizer a cara 30 segundos. Mas...
 com um pouquinho de ajustes, a gente consegue deixar exatamente cada fala no tempo certo e já no formato, sei lá, SRT pro YouTube, então essas duas coisas dá pra fazer bem tranquilo assim. É uma coisa legal, já pensado ali, do ponto de vista de transcrição, não sei se já tá pensando aqui, mas enfim... durante o texto, né, durante a fala, na verdade, durante o vídeo e tal, enfim... vão ter coisas que vão estar erradas mesmo, sabe? Tipo que a pessoa fala e se corrige. É...
 Nessa hora, essa transcrição não precisa se corrigir, entendeu? Então, se o negócio já está fazendo uma análise de contexto, a coisa toda, ela pode corrigir, inclusive, tipo, essas partes que estão erradas. Sim, isso aí já tem duas perguntas. Seria só naquele... Quando a pessoa dá aquela gaguejada, ou quando ela fala uma palavra errada depois se corrige, mas também quando ela... Quando tem essas interjeições que pegam um pé...
 o tempo que tal coisa, justamente que tudo daria pra gente tirar. É justamente isso, do ponto de vista de execução do trampo, porque o vídeo não tem roteiro, entendeu? O vídeo que a gente vai fazer essa transcrição, ele não é roteirizado. Então é justamente esse um dos trabalhos, que é roteirizar.
 Tá ligado? Então o vídeo é tipo no FreeFlow. Então o cara responde perguntas, né, durante os vídeos. E ele responde com base nos conhecimentos dele. Ele não abre um Google ou alguma coisa ali para pesquisar e falar, né. E antes o vídeo ir para o área e também não pegou a pergunta antes para elaborar em cima e fazer uma pesquisa. E aí na hora do vídeo ele já faz um negócio que tipo está
 pouco roteirizado, não, é justamente isso. Então, muitos desafios deles também, quando a gente falou daqueles ansios de transformar em roteiro, é por conta disso. Transformar em roteiro vai ajudar a gente depois... Tipo, ajuda a gente a fazer a transcrição de uma maneira mais contextualizada e que fique melhor nessa transcrição. A gente consegue fazer um roteiro, e na hora que a gente conseguir traduzir isso para outras línguas, ajuda também nessa parte de roteiro, de ter um negócio...
 utilizado, que não é uma coisa que é uma fala livre, com também uma contextualização na tradução, por um negócio que não fica aquele tradução literal. Hoje o próprio Google Transmit já usa contexto para traduzir. Então é mais só colocando isso verbalizando aqui o que eu estou pensando, já pensando na aplicação acontecendo. Você sabe, né? Ah, então meio lanseguido... Mas isso é importante assim, desculpa de cortar.
 Mas só reforçar, para a gente não esquecer, que esse trampo é um trampo de transcrição, mas na verdade é como se fosse uma IP de transcrição e roteirização. Transcrição e roteirização. E faz assim, se a gente quiser se chamar... A gente... Eu tinha pensado já nesse... Qualquer estratégia que a gente vai falar, porque acho que esse é um ponto importante de se abordar.
 imaginando um mundo onde tudo seria possível. Como que a gente poderia usar os dados dele para poder gerar esses roteiros? Qualquer... Algumas estratégias possíveis. Ó, os sugestes. Beleza, faz o quê? Tipo assim, é... Eu tenho como extrair conteúdo do vídeo, juntar, transformar todos os vídeos dele em texto e alimentar um bagulho.
 mas se a gente conseguir definir uma estratégia no dentro de um escopo mais fechado, primeiro quanto mais simples, a estratégia é melhor, e isso também vai dar uma visão do que precisa ter feito para atingir o resultado. Eu acho que a gente pode simplificar bastante. Todas essas coisas que dá para fazer com esse material que vai ser decupado e que a gente vai ser alimentado numa base de dados, enfim, vai ser aquela nossa matrix novenzinha de um arquivo 1, tá ligado?
 O que a gente vai fazer depois com aquilo, a gente pode depois estudar. Acho que talvez a gente possa fazer primeiro e talvez esse possa ser um pulo do gato, tanto para mandar para ele e fazer um projeto para ele, mas também depois pegar esse projeto se for o caso e plugar em qualquer outra coisa que é uma ferramenta de roteirização. Tive uma ideia. Tive uma ideia. Tive só uma dúvida antes disso. O que ele vai querer usar, eu só fiquei na dúvida inclusive outro dia, é só baseado nos vídeos que estão por aqui.
 pronto ou ele vai querer fazer alguma coisa no vídeo cru antes de dar uns cortezinhos assim porque funciona da mesma forma mas ele poderia por exemplo transcrever um vídeo inteiro cru e a partir do vídeo cru eles já conseguem ver pelas falas para não precisar assistir todo vídeo e selecionar melhor os momentos que vão ser cortados ali depois é isso também uma coisa que pode auxiliar na edição do vídeo para que
 quem for fazer, mas porque esse pode fazer só dos vídeos que estão pronto, a gente inclusive poderia já começar a rodar tudo em cima dos que ele já tem e mostrar alguma coisa em cima disso, só base de dados já tem, só precisa trabalhar em cima dela com os vídeos que já tem também. Eu acho legal, a gente pegar um vídeo que já existe, transcrever ele e ver como é que vai cuspir esse documento, então eles já conhecem esse vídeo. Tá aqui, ele já é o primeiro sample, agora o que a gente vai fazer com isso?
 Isso, a gente precisa transformar isso num roteiro, sabe? Então, mas o que foi assim? Foi fecha. Por que roteiro sendo que tipo isso aqui já é uma transcrição de vídeo que já foi feito, o DeFord foi roteirizado? Porque isso, na verdade, é o jeito que o negócio vai pensar e com os peças e informações, aí depois você escolhe como é que você quer. Então isso que ele tá falando de repente, que tem um pré-cut? Não, tá, e é outra coisa, é outra parada, não tem a ver com a autorização, não tem a ver com... Não, mas olha só, isso daí que a gente fez, tem dois modelos, o modelo que tá com o TimeStand,
 O modelo 100 foi pensado justamente para que fica mais fácil para ir trabalhar em cima, porque a partir dela dá para criar pontos mais interessantes, roteiro, tudo partido desse base que seria a transcrição crua. Então a partir daí a gente pode fazer um monte de coisa, é só questão de trabalhar o que a gente quer fazer, basear nos dados daquele vídeo em si. Mas isso é um vídeo que já está...
 Tá pronto, na minha cabeça já tá autorizado, porque já foi pro ar, entendeu? Então, ainda não entendia essa parte de roteirização quando o vídeo já tá pronto. Beleza. Vou falar o que eu vejo, a Thé também colocando um pouco do que eu conheço de produção de vídeo. É interessante gerar, usar esse... não sei como ainda, né? Se vocês usarem o conteúdo para ajudar, ou gerar no
 para as pautas de repente ou ele trazer, imputar as pautas do interesse dele e a gente usar os dados que ele já tem para tentar acamar a ideia que ele colocou. Então, acho que é isso dentro do estratégico, só que é tipo, é predição, não tem exatamente... Então, mas isso são só sugestões para outros vídeos. A gente tem que entender que assim, o formato desse cara de gravar vídeos, tá ligado? Ele só liga a câmera e vai... Lembra que é um...
 um produtor de conteúdo específico, mas pelo que vocês já estão me falando aqui, minha cabeça também já está fritando e dá para dar isso para outras coisas. Então, por isso eu estou falando que esse negócio de roteirizar já é muito legal, porque parte da demanda dele, que a demanda dele é, é um free flow ali, eu não tenho uma pergunta, só que a gente tem uma necessidade de transformar esse free flow também num roteiro mais côntho, organizando mesmo. Então, assim, vamos imaginar que aquele vídeo
 Como que você enxerga a utilidade do roteiro reverso? A utilidade do roteiro reverso é que você vai conseguir ter um jeito daquilo que está organizado, sabe? E essa informação organizada você pode fazer várias coisas com ela. Justamente fazer as traduções depois, justamente depois pegar esse negócio e poder filtrar ele e fazer uma sugestão de novas,
 novos temas. A gente pode ir além, né? Criar shorts e afinas... Eu ia falar, quando eu estava falando que veio ideia de algo que dá para imediatamente fazer, inclusive pegar um sample de vídeo e gerar em cima, ele faz um vídeo giganteiro, escolha, até abrir aqui o Instagram dele para ver o tipo de vídeo que ele posta em stories, etc. Mas de repente, podia pegar trechos de falas fortes dentro de vídeos mais longos dele e falar sobre aquele assunto para gerar um short para o YouTube.
 para Instagram e etc. Por isso, então. Por isso, mas estava me perguntando qual é a necessidade de criar o roteiro. O roteiro é para isso. Então, assim, qual que é o lance do roteiro reverso? Na verdade, o lance do roteiro reverso é que você vai organizar as informações. Ah, o lance que ele falou de ter um precante, de tipo dentro desse monte de coisa, desse monte do vídeo que está lá, desse monte de fala, de repente já está. Quando você coloca isso no roteiro, você vai conseguir cortar.
 e saber onde que estão os pedaços que vai ser realmente o conteúdo do vídeo. Tá ligado? Nesse lance do pré de roteirizar, a gente já está pensando em uma ferramenta pré-vis no futuro também. E na hora que o cara gravou o vídeo, esse vídeo gravado realmente depois ele vai para um lugar, ele é editado e depois ele sobe no YouTube. É, rapitão, você está gravando isso aí?
 no YouTube e fora, não é um vlog, né? Então ele grava, os cara edita, tem esse trampo de fazer uma decupagem, importar uns negócios, mas não corta muito, porque não tem metedição, o cara não para de falar, porque nós estamos falando aqui, entendeu? Em cima de um raciocínio. E aí, o que acontece? Se a gente também cria o roteiro, faz a ferramenta decupar esse negócio e cuspir um roteiro, o que vai acontecer? A gente sabe que é um vídeo de tipo uma hora, dentro da dinâmica de vídeos que o cara...
 ou a gente pode depois em algum momento setar isso na plataforma também, a gente pode ter tipo 1, 2, 3, 4, 5 breaks entendeu? Depende do tamanho do vídeo quando o tamanho do vídeo dele às vezes vai ter, sei lá, 2 breaks, 3 breaks porque são perguntas diferentes e aí na hora que a gente cria o roteiro isso também já tá quebrado lá pra ele então eles são tudo informações que na verdade se jogou aquele vídeo bruto você pode até jogar o editado também mas aí o lance é você jogar o bruto você joga o bruto, pare, processa
 a porra toda. A ultima parte está falando mais o sentido de futuramente ele usar isso daí para pré-processar o vídeo antes da edição que ele sobe. Ele o César que deu essa ideia. É realmente interessante. A gente pode um passinho a mãe porque viável é só é mais bom de obra mas imagina que a gente tem essa transcrição o cara vai botar o vídeo ele a gente monta para ele uma forma de edição onde a edição vai mostrar a falinha ali já tá ligado.
 junto com o vídeo enquanto é de tanto. Então, pro editor é até mais fácil, porque ele vai ter exatamente o início e fim da fala. Tudo depende, você tem que dar um cheiro do quanto... Não, não, não, eu tô viajando aqui, só tô falando que existe a possibilidade. Sim, com certeza. E seria do caralho, porque já tá quebrada e tal. Tem umas ferramentas que, uma vez, eu já usei, tipo, de fazer decupagem de filme e tal. Esses caras fazem isso, assim, tem a... Tem um slider ali, você faz um... Tá como se...
 Se tivesse abrindo um Google Docs de film e aí você faz os comentários onde você quer nos trechos, no YouTube, mas acho que a gente não precisa ir nesse grau de edição, assim, até pode ir depois e ver preço e tal, mas... É, pode fazer um sampa manualmente de algumas coisas, assim, falar, mano, isso aqui a gente gerou um bagulho super rápido só para fazer uma demo, dá para melhorar mil vezes. Assim, o lance aqui nem... Ih, essa célula de criar hotel...
 isso pode estar em algum outro lugar e tal, que não necessariamente precisa ser só pra ele. Mas agora, pra resolver esse trabalho pra ele, acho que é legal a gente coletar, já ir escrevendo e colocar as possibilidades. Ah, pode ter um editor, né? A plataforma processou o vídeo, ela já vai decupar, já vai mostrar, já tá cortado, se quiser, você já coloca umas transições ali no meio, já faz o canva junto, aperta o play e já sobe no YouTube. Você nem precisa abrir o YouTube pra subir o vídeo, tá ligado?
 Tudo isso, sei lá, via browser. É possível, é possível. Vai gastar um... em boas máquinas lá do GFP, você vai gastar, tá? Mas até dá pra fazer. Uma ulância, eu acho, é na minha visão, tá? O que eu acho que a gente pode vir aqui, já com tudo isso que vocês estão falando, é... foca numa ferramenta que transforma tudo isso que tá falado em roteiro. E, Felipe, você já viu milhões de roteiros, você sabe como é que tá quebrada as minotagens de roteiro e tal.
 Então, é isso, tentar meio que quebrado nas minutagens de roteiro, das falas, com respiros e tudo mais. Pô, você já tem isso, ali um álbum. Aí, depois, quando você traduzir para uma outra língua, perfeito também, até se você precisar depois de umas coisas que a gente até conversou sobre, que é, ah, beleza, vou traduzir esse negócio, vou traduzir dublando. Só que eu vou contratar um native speaker para dublar esse negócio, para sair com o accento.
 só que aí porra eu preciso da voz do Cristian já vou jogar no modulador vai sair com a voz do Cristian aí você pega e coloca no e aí muito louco nvd da vida e a boquinha fica se mexendo com a boquinha da tradução que foi filmado do outro cara né? manda um trem mas vai... então, ai, inclusive quando surgiu esse negócio aí esse papel foi atrás
 Eu entrei numa seção como Crazy, que comecei a pesquisar, batia dentro. Eu achei uma parada. Os caras fazem... É só manomente, é tipo uma equipe que nem a gente, assim. Eles, ó, que a gente tem essa taxa, que é contratar nós sem mil dólares. De ficar mexendo a boquinha. É, né? Mas eles estão vendendo para Hollywood a solução para traduzir os filmes em todas as línguas, tá ligado? Mas aí imagina, você... Só modular a voz já é mais fácil.
 Então, não imagina quem joga mexer a boca, mas só vai dublar. Só vai dublar com a voz dele, perfeito. Então, e aí, o roteiro, quem vai ler o roteiro? Entendeu? Vai ter que ser alguém que é uma pessoa fluente. E ela vai ler que roteiro? Cadê o roteiro? Vai ter que fazer o roteiro não tá pronto. Não, é traduzido no vídeo original. Então, mas aí, um roteiro, para a pessoa poder ler. Entendeu? O que que é só poder ler? Mas o roteiro já não é a transcrição crua. Oi? No caso, eu tipo, pensando que o...
 A pessoa que leria o roteiro seria o dublador da outra língua, no espaço de usair isso. Esse roteiro, o gerão seria a transcrição com o tempo? Sim, é o télgelege, transconverte o texto, não deu a sintese aqui? Tipo, você mandar um texto, ele fala numa língua e aí você só sintetiza a voz. Então, nem precisa do dublador? Não. Ele fala melhor aí, ele fala o roteiro, o roteiro...
 Eu estou falando tudo isso só porque qual é a necessidade do roteiro, entendeu? De estar estruturado em forma de roteiro. É só se ele for usar as informações, porque internamente é só registrar tudo. A maneira com que eu ia ler as coisas, estar no roteiro ou não estar no roteiro não faz diferença. Põe ali no texto do Christian e põe para ele ler um testinho aí. Eu só logaco isso aqui. É assim, eu focaria nesse lance de criação de roteiro e dali.
 todos os plugins possíveis que a gente pode fazer. É tipo assim, é uma bagulha de transcrição com roteirização. Aí entra essa vibe e dá brisa. Qual que é a ferramenta? A ferramenta faz isso. Ela faz uma transcrição. Ah, mas a transcrição já tem várias, né? Ela transcreve e roteiriza. Tá, mas o que ela faz com isso? Ela faz um monte de coisa. Por exemplo, eu posso legendar um vídeo com essa transcrição e com esse roteiro. Aqui é o seguinte, tem esse bagulho que é um instante voice clone.
 E ele não vai ganhar tanto em intonoção, mas é tipo uma parada que está para fazer uma demonstração com como seria mais ou menos o covarde dele. E aí ele tem esse Professional Voice Cloning que tem que pagar a mais. Deixa eu ver quanto custa. Professional Voice Cloning. Cloning, cloning, cloning. Instant Varsalon. Instant Varsalon.
 Eu estou de mais congresso, bora esse papel, eu vou escolher. Tem que ser isso. Escomem later this year, não tem. Eu não anso ainda, eles anunciaram um bagulho. Eu imagino que até se enrolar esse papo aí já vai ter. É só um testinho, só pra ver que vai sair na IP... Vou fazer o esquema agora. Na IP Google ou na IP Voice, né? Pega uma voz boa já, porque a gente... O usando no caso de uso que a gente queria, eu gostaria de transcrever para inglês.
 Por exemplo, nem precisa pegar a sample dele, só pega esse textinho aí dos primeiros 30 segundos, bota para converter para o Google ali, para o GPT e cola aí dentro para ver a voz. É basicamente isso que a gente faria. Como é que vai de novo? Ó, abre o transcription, copia qualquer linha aí. Então, pega ali, ó, então a arroguitura é no fundo.
 uma ruptura tecnológica. Mas só pegar aqui no começo, porque eu consigo até se encaixar fácil. Tudo foi. Valeu. Basicamente, você só vai mandar isso aí para alguém para converter para ti para inglês. GPT. Entendeu? E eu ia falar alguma coisa aqui para vocês e já passo logo lá, né? Esse. Pronto. Traduz família.
 para que inglês? é né a voz em inglês a default só tem que deixar os segundos depois, call no 11-11 e é isso aí só que imaginando que isso já viria transcrito em inglês né não teria esse passo aí que tem que fazer, é qualquer um que se tivesse feito bom
 Certo, acessando aqui. Deixa assim mesmo, né, monolingua, não sei. Essa aqui no caso é com uma voz que já tem, né? Não é? Estraduziu a tradução. Estraduziu a tradução. Valeu, valeu.
 Várias séries ali e esses que são em inglês especificamente eles tem umas entonações mais da hora não fica muito rebótico Esse que o Felipe pegou não sei como bom é mas a gente poderia usar uma coisa assim Ou algo ainda, nada em pé de a gente treinar a voz dele e aí vai ser ele falando inglês Isso pode ser, fica mais forte E isso aí é o potencial que eu vejo, se a gente prosse uma ferramenta essa aí eu ia preferir ir por esse lado A gente por perecer
 esse serviço não ia ficar tão bom em tonação mas o avó ficaria exatamente em volta Agora a gente só pode testar um melhor
 As vezes não temos cutnesses, usamos a expressão subnesses. De verdade, essa é uma série mini que adereça em todas as variantes, o problema fundamental para a análise psicólica e também para a subjetividade, que são as divis... Traste essas divisões para a forma mais moderna do que o subjeto. Então é isso. Tralco aqui, mete um... Espanola.
 Ah, ah, mismo caro. ¿Para que habla español también? ¿No lo has cubierto? Como no tenemos cutnes, usamos la expresión subnes. De hecho, esta es una minisería que aborda en todas sus variantes. El problema fundamental para el psicoanálisis y también para la subjetividad. Esa es nuestra división subjetiva. Es una esplenicia. Entonces podríamos rastrear estas divisiones hasta la misma formación del.
 do jeito moderno. Então, isso é tudo. Parece meio americanizado. Que só é em inglês, esqueci de trocar. Mas ficou até bom para um bagulho. Era para sair um espanhol dos Estados Unidos. Entendeu? Um espanhol americano. Agora, seja está mais. Como não temos cutnes, usamos a expressão sobnes. De hecho, esta é uma miniserie que aborda em todas as suas variantes
 y tal para... ¿Cómo te está? O Antonio, Antonio, parece ser legal. Es legal, es muy legal. No tengo inglés, un español y así está. Mucho lenguado. Como no tenemos cadnes, usamos la expresión subnes. De hecho, esta es una miseria que aborda en todas sus variantes el problema fundamental para el psicoanálisis y también para la subjetividad, que son nuestras divisiones subjetivas. Entonces podríamos rastrear estas divisiones hasta la misma formación.
 de um sujeito moderno. Então, é isso tudo. Vamos colocar isso no vídeo? Ó. Bom, galera, é isso aí, meu. Acho que é foca nesse lance da ferramenta de roteiro, roteirização, óbvio que tem a transcrição, mas é isso. Eu acho que se a gente apresentar um negócio de roteirização e, óbvio, com esses features de transcrição, transcrição contextualizada, correção de possíveis vícios, essas coisas.
 coisa de linguagem é um é abre um vídeo dele pra gente ver junto aí e enfim e aí pôs isso como roteiro e a legenda do vídeo é isso que estão precisando agora é ligado aí depois é o que é de quatro dias atrás depois é qualquer coisa aí a gente pode ir para gostou se ele quiser o que eu tô de fôlego
 Ó, máxima da nossa querida Marília Mousque foi nossa baixista vocalista de todas as bandas que originaram a equipe produtora desse super canal YouTube, Moonie. Ele falou em ativo. Mas tocou ser elepe. E... Tem uns detalhes que eu peguei quando eu botei para traduzir que ele falou, por exemplo, bem estilo.
 E aí eu... Estilharam certo Só que daí a transcrição ficou como um styler mesmo E quando eu joguei para o GPT para dar ajustado para mim, ele ajustou para o Stealer É o tipo de coisinha que eu esperava que fosse ajudar depois Então, por isso que eu ia pegar uns 95% que dá para garantir Porque ela vai pegar contextualizado nesse tipo de casa É assim que é tipo a sotaque do carro, o jeito que ele fala, ok? Mas dá para ajustar
 Então, e outra, o que eu queria fazer é literalmente um negócio onde ele, na hora que dirá, ele já consegue literalmente copiar e colar ali o negócio pro YouTube já colocar legenda, tá ligado? Deixar no formatinho, redondinho pra ser usado no mínimo de esforço possível. Eu vou botar um prática aqui. Às vezes é porque não deu tempo. Às vezes não, tenho certeza. Vamos ver um vai, de 12 dias atrás, não, 12 dias atrás tem que ter já. Não, não, não, não, os caras estão frutidos.
 O vídeo que eu peguei é Rooftura, que é o mesmo desse que eles mandaram. Esse ali, ó, sabe, sabe, sabe. Um que tem um negócio verde no fundo. Esse aí é o que eu... A gente faz um trecho dele em três línguas, legidado, e aí manda de Dendo. Não tem. Então a gente pode fazer tudo do baseado nesse vídeo. Beleza, só tentar ver um vídeo de um ano atrás para ver se tem alegria.
 só que vocês verem um arquivo também, eu acho que... Não, você é de um ano atrás até que é velho é tipo, isso, tá ligado? Não é só tudo bem, mas eles... A unha, a legendagem e provavelmente... Foi manual, né? Isso! De um ano atrás, não tem! Porra, que estranho! E potência sexual! Então, mano, ele não tem a parada... Vou botar mais um... Não, mas basicamente eu tenho de ser...
 Ta aqui no canal, Burnout. Também não, só gerador automaticamente. Ou seja, ele não paga o serviço que ele falou, que pesquisou pelo jeito. Ele tava atrás da solução, mas não contratou, entendeu? É, não, não, eles não contrataram, estão tentando. Tanto é que eles fizeram também umas coisas via de título via chat gp dele, estavam me falando que não gostou muito, também ficou meio... Ficou meio bosta, uma galera meio que reclamou, assim... É, isso aí.
 você só vai conseguir fazer mesmo com Farry Toney, porque você baixa todos os vídeos dele e vai gerar um padrão de como ele gera os títulos dele com a semandica por trás da balaça. É, e assim, outra coisa que eu acho que é legal a gente trabalhar é trabalhar com o pé no chão. Então, assim, se a gente já conseguir fazer essa parada que a gente está falando aqui, do roteiro, da transcrição, deixar a bala ali prontinho, poder traduzir nas línguas, mas assim, na verdade, posso usar trás. Recrição.
 bacana, com geração de legenda, já fodaona, contextualizado, essas coisas, né? O César falou, o Ben Styler. Pode colocar isso no apresentação que a gente manda pra ele. Olha, inclusive durante esse demo que a gente preparou, a gente pegou esses detalhezinhos, o próprio E.A. já corrigiu pra ele saber que a bagaça está acontecendo. É isso aí, é isso aí, beleza.
 o pacote fala ó, tá aqui e custa tanto, entendeu? tem que chegar assim, tá aqui e custa tanto cara, pula atenção, quero, tá ligado? vou contratar essa porra aí, tipo um subscription, tá ligado? às vezes de um bagulho que a gente fez, não é dele a gente vai fazer nosso, entendeu? e ele é o beta, e deixa rodando eu não sei quanto custa, entendeu? mas vai custar a X, faz o benchmark com aquele lá aqui vocês falaram que custa o cara pra caralho e ele também falou que custa o cara pra caralho
 isso que eles não contratam, eles usaram uma coisa meio free, né? Mas é isso, o canal gera um dinheiro, né? Tem um número interessante de visualizações ali e eles fazem um reninho aí, aconteceram muita coisa, mas tem um negócio aí, entendeu? Tem muito vídeo, né? Vê quantos vídeos tem aí? 638. Tá ligado? Tá longa, tá ligado uma coisa na coisa. Mão Lancia, até porque eles querem fazer isso?
 para poder colocar em outras línguas, legendar em outras línguas e possivelmente dublar esse negócio. Então assim, vamos com calmo para de repente esse cara colocar, nem que seja alguma coisa um pinga pinga, paga um servidor de alguma coisa para fazer esses testes e a gente vai evoluindo nessa mesma ideia, de repente pode ir travando outras coisas, ó, conseguimos fazer, fizemos um bagulho foda aqui de tradução, amigão, fizemos uma tradução, custa mais tanto, ah, mas não quero pagar, não tem problema, a gente não para lela.
 Então vai, de repente, ativando isso, deixando a ferramenta disponível pra alguém comprar também. Ó, fiz aqui um bagulho aqui, mano, muda sua voz, caralho, você não quer comprar esse bagulho e tal, não sei o que. E aí, é isso. Vai aí de baguzinho. Pra algumas coisas básicas, já tá no nosso roadmap inclusive, né, tipo a porra de transcrição e tal, tal, tal. Mas tipo, umas paradas muito customizadas, assim, já começa a sair um pouco do que a gente tá vendo que vai fazer. Next, a não ser que...
 entre um cash flow ou respeito. Tipo assim, não é viável desenvolver uma solução para esse bagulho agora, negociando um modelo de subscript. Sempre uma grana na frente. Ou se a gente não resolveu investir uma grana para desenvolver o bagulho e fazer como você falou, ah beleza, vamos fazer a nossa plataforma. Mas você tem que ter um gasto que você não não sai. Pera lá. Beleza. Ele vai ter que bancar de alguma forma, mas a gente fala pra ele... Com direto e diretamente. Vocês ele entram como...
 pensando é, o dinheiro que você inventou para fazer a plataforma, a plataforma é dele também. Então, eu estava pensando no modelo que, de repente, essa, esses vídeos ajudassem a pagar esse negócio para dar essa função para ele, para ele gerar mais grana com esses vídeos e assim sucessivamente, inclusive na sede de tradução de línguas e tal. Mas a gente pode chegar numa outra...
 Tem uma quantidade, imagina que a gente já desenvolveu o bagulho, baixou a mão, todo o vídeo dele, mandamos pro AI, o AI conhece o cara do avesso já. E aí, pra começar a gerar coisa em cima disso. Ah, vamos legendar todos os 638 vídeos, vamos gerar toda dublagem em inglês e espanhol pra todos os 638, se não vai sair barato, já pego. Então, tem o custo operacional, tipo assim, tem o custo de desenvolver a tech, tem o custo de operar, e crane começar.
 que aí precisa ser... Mas aí a gente vende a ideia pro cara e às vezes vende pra ele ser só... Dá pra vender com geração. Dá pra vender a geração, inclusive. Tipo, eu não vejo talvez um modelo de subscription pra esse caso específico como envolve o uso de várias APIs e... áudio e texto, e GPD, e o caralho. E tipo, olha, pra fazer um vídeo assim, tipo, o bagulho custa...
 tanto o minuto do vídeo, para ele saber o custo operacional por trás da bagaça, e a gente desenvolveu um modelo de negócio em cima disso. Você é um cara que dá para a gente conversar a mesa aberta? Tá, porque isso, assim ó, o dinheiro para fazer essas coisas, poderia vir desses vídeos, mas... tipo cobrando dele. Do ponto de vista se a gente coloca ele lá dentro, e ele vira um partner mesmo, ele vira um...
 É um apoiador, um socio do produto e tudo mais. Aí a gente consegue pegar, aí tem que ver o folego dele, mas a gente pega outros dinheiro e usa ele próprio. E usa ele como beta-testing, exatamente. Ele tem material suficiente para ser um dos melhores tipos de beta-testing que a gente pode ter para esse tipo de solução. E aí o cara tem um livro, palestra, aí dá para começar a usar isso. E usar os outros para se trazer. Dá pra fazer bastante cuidado.
 Tem muito, tem muito coisa ali mesmo. Então, mas vamos lá, próximos passos. Desenvolver ou pensar como desenvolver ou o que precisa ser feito para desenvolver o negócio que vai fazer uma transcrição e uma roteirização de um vídeo, que ainda não foi para o YouTube, mas é de um vídeo de repente um free flow. Você vê, esse último que se abriu ali e tal, ele tinha até alguma coisa de roteiro ali, chamou uma participação especial e tudo mais, mas ainda é que os vídeos...
 Não tem não isso, inclusive aquele que vocês estão trabalhando lá, qual que é o vídeo? É ruptura, só para ir aqui lá porque eram mesmo que eles usaram de exemplo que foi mandado. Os homenamam o vídeo aqui. Lembra, olha, tá rolando uma captura aí, pá... É uma produçãozinha. Acho que é bem produzido. Isso aí é uma cena da série pelo que eu entendi. Esse cenário também é cenário da série, cara. Dá hora.
 tem uma série que chama Roptuz. Isso, ele tá falando sobre isso aí. É esse vídeo que eles usaram no exemplo e botaram trecho, não tem. Tem um mil e oitenta premium agora que eu fiquei. Esse é o seu sábio da Ressentadecidente, né? Mano, eu comecei a ler a transcrição do vídeo e me querer dizer pelo assunto, peraí. O cara era bom, faz uma análise boa. Então, aí que tá o polo do gato?
 esse cara é muito cabeçuda, pra galera cabeçuda, entendeu? Tipo assim, pra tentar dar um exemplo meio tosco aqui pra fazer essa análise assim, deixa eu pensar aqui que eu consigo trazer de exemplo meio de Deus, perfeito? É... Puts, é difícil falar algum exemplo assim, mas tenta comparar um site de fofoca, tá ligado? Hum, um site de fofoca.
 de cinema, um IMDB da vida, sei lá, tá ligado? Os dois vão falar sobre cinema, sei lá, o lançamento do Veloso e Furiosos 10, sei lá, entendeu? Um vai fazer uma análise do tipo assim, sei lá, Vin Diesel, os músculos, o Tá Velho, o Barrigudo, né? E o outro vai falar, puto, o filme tá fechando a saga, não sei o quê, é uma análise mais técnica, tá ligado? Inevitávelmente, o de Fofoca vai ter mais visualização do que o...
 esse brother é um pouco isso, então assim, ele é psicanalista, ele faz análise, muita coisa e esse canal me proponho muito com análise de questões sobre psicanalises. Hoje em dia ele é colonista no wall também, então ele escreve no wall sobre cotidiano através de psicanalises, mas muito sobre séries e coisas que estão acontecendo, enfim, uma série de coisas nesse sentido, tá ligado? Só que é isso, ele não consegue ter um alcance, tá?
 e o seu bicho dele também, que você está muito mais na galera acadêmica, na galera que quer escutar de repente uma coisa mais cabeçuda, do que da galera mais normal, só que às vezes está interessado, tipo o César. O César era psicanalista? Não. Não, não. Não de eu sei, não. É que eu de eu sei. E o cara está fazendo uma análise aqui, ele tem os pontos dele, ele é cabeçudo, ele faz essa análise que não é uma análise...
 cinematográfica da parada, ele faz uma análise psicanalítica da parada, entendeu? E isso também traz coisas interessantes e tal para você estar consumindo. E que hoje em dia tem até uma vertente que acaba consumindo mais. Então a ideia toda dessa coisa é como que também faz chegar para mais gente esses conteúdos. Eu tive uma ideia enquanto você estava falando de novo. Acho que eu tinha comentado isso e o assunto ressurgiu agora. A gente meteu o bote para fazer uma análise de sentimentos das coisas tóxicas do Twitter e Traseão.
 é uma pele fala sobre o que estava viralizado, tá ligado? Ele fala sobre as distorções da... Então, esse é o lance que a gente estava... É onde a gente está aqui na conversa. E é justamente de alguma forma também poder alimentar ele sobre coisas que estão viralizando e tal, para fazer uma análise em cima. Ele já faz um pouco isso. Mas talvez seja... É, é baseado em tudo que...
 O cara já faz, o que eu vejo de vantagem é a gente usar isso aí como porta de entrada para ele conhecer, mas a gente tem muito mais para oferecer para ele que ele nem sabe, a gente não sabe também. Porque a pouco ele vai fazer uma pergunta, dá para fazer tal coisa e aí é dois palitos para fazer a parada. O que é o outro? Então é supervário. Quanto mais gente de ramo diferente começa a ver essas coisas de AI, mais potencial vai ter toda a solução. É, e não é isso. É, e não é isso.
 interessante assim se vingou alguma coisa porque o cara é do metiê assim entendeu o metiêzinho uma galera uns cabeçudão de grana que segue ele né esses caras que a gente quer que é eu vejo que o dinheiro desse business aí não tá no usuário final que é o que é o paciente dele os pacientes dele eu sou nada ele nem sabe seu Paulo não falou
 Porque o meu dinheiro pra ele realmente não conta. É, realmente não é nada. Não conta, né? Ele ainda... Tipo, é indiferente eu pagar pra ele, não mexe no orçamento dele. Agora tem uns outros caras que me com certeza mexe. Hum. É, eu nem sei o que eu tô fazendo lá com ele. Eu não sei como que o cara não me dispensou ainda. Não. Eu já tô tipo uns dez anos fazendo na vida. Acho que é meio por isso, talvez. Talvez seja diferente. É um lugar confortável pra todos os outros partes, né? É, é, é. Se você já conhece ele... Eu não fico enchendo essa coisa.
 para às vezes cancelar no meio do rolê não ficou tipo com certeza deve estar um galá no laque deve estar pitinho né come assim que acera não pare pessoalmente quem paga meu parado a secretaria dele fala ai Rafael nossa desculpa deixa eu ver precisar cancelar e tal é a sua você quer remarcar para algum outro dia eu falo não sei se vai que vem a nós porque é mó dinheiro entende então quando pula para mim pra mim tá bem ansioso até bom
 Se eu faltar, eu tenho... Entendeu? Mas se ele não me paga, né? Então eu vou falar isso pra ele um dia. Se você faltar, você vai ter que me pagar. Acho que tem uma coisa aqui que... Faltou falar o acreditado sobre esse assunto? Poco. Ah? Transcrição e roteirização. É isso. Transforma o bagulho não naquela decupagem. A gente precisa de um roteiro. Acho que isso é o pulo do gato pra parar da toda, entendeu? É pegar uma conversa, tipo que nem a gente tá falando se a gente quiser...
 se transformar isso aqui num vídeo, a inteligência artificial ia falar assim não demorou, vou fazer um roteiro. Sabe aquelas brisas que os caras fizeram no começo do chat GPT? Até te mandei esses vídeos lá no começo, muito tempo atrás que os caras fizeram uma sketch pedindo para o chat GPT, tá ligado? E aí a sketch é uma fala assim, ah, os caras começam a zonar, você viu isso aqui? Tem uma inteligência artificial, ah, esse aqui é o... então fala qual que é a capital de não ser aonde?
 Certo, ai, qual que é o capital do outro? Aí o outro, ai é tal, ai eles, ah pô, interessante, né? Ah, mas não faz muita coisa, mas pô, isso a gente pegasse e criasse uma sketch usando essa inteligência artificial, aí aparece lá, tipo como se fosse essa parte da linha já escrita pela própria inteligência artificial, que a sketch era aquilo que eles estavam gravando, tá ligado? Então a inteligência artificial se comportando do bom ponto de vista digital, ofertando
 O interrúdo para a galera lá. Eu nem sei o que eu estava falando isso no começo. Mas era uma coisa importante. Do pun de vista de... Ah, é um negócio foco, né? Eu estou perguntando. Eu vou colocar em roteiro e a partir do roteiro dá para fazer mais parada. Vou transcrever isso que a gente falou agora ou se as vezes...
 Não, lembrei. Posso lançar nos canteiros? Eu coloquei o bagulho aqui, mando o arquivo e eu transcrevo aqui rapidamente. Tá, você compara aqui agora e não... Não, não, vamos terminar aqui. Termina aqui, a gente pode, que assim, o lance é... Por que que precisa fazer um roteiro, tá ligado? É porque o arquivo não vai ficar só uma decupagem crua. Se a gente roteirizar ele também dá um acabamento, tá ligado? Pra você poder ter esse arquivo de base. Então, o que eu tava falando aqui, se a gente quiser se transformar...
 Nosso papo aqui que a gente está tendo, num vídeo de YouTube que aí o negócio vai estar setado em transformar aquilo em um vídeo que você vai gravar ou já foi gravado. Na verdade, um vídeo já foi gravado, mas você pode gravar ele de novo se você quiser. Então, por exemplo, nesse caso do que a gente está aplicando é de um vídeo que já foi gravado. Mas essa ferramenta, se a gente quiser, a gente pode usar outras coisas para ter sites para virar em roteiros e gravar em vídeos produzidos.
 Então, acho que esse é o grande delas, de pegar alguma coisa para o estar, ter uma conversa ou alguma coisa aí, como você pode absorver isso e transformar no roteiro para alguma coisa que você pode produzir depois. No nosso caso, já vai estar produzida, a gente vai usar os ácites dessa transcrição para fazer legenda, traduções e, de repente, servir de roteiro para dublagem,
 E aí, como próximos passos, eu acho que é entender como é que isso funciona, viabilidade técnica, tempo, grana, o que que consegue fazer e segurar a onda do ponto de vista de desenvolvimento até aí, para essa entrega, sem traduzir nada, sem nada. Se quiser, acho que pode... Então, vamos nos demorar para usar o que eu já tenho de serviço contratar, por exemplo, esse taxi to speed que eu cozei aqui, tipo, eu pago, tem uns caras...
 Tento aqui, eu não vou conseguir fazer um bagulho com aquela itonação da hora, mas eu consigo fazer um trechozinho de 10 segundos de ele ver o vídeo dele dublado, tá ligado? Então, assim, o que a gente pode fazer, e é isso é ótimo. Não, não, eu acho que é ótimo pra gente ter de demo e aí falar, ó, o seu trampo, o que você precisa agora? Transcrição, legendagem. É a burgulha da sua legendagem, Paulo, tá aqui. Tradução e legendagem, pum, tá aqui.
 O que a gente pode fazer também? Dá para fazer a parte de dublagem, dá para fazer a parte de produção de conteúdo, dá para fazer a outra parte de insight sobre leitura, de sentimento de Twitter, algo assim, com tudo que está lá de psicanálise e cuspir algumas coisas de correlação, de coisas com coisas, tipo, nem mar, mandando fazer logo artificial com narcisismo, sei lá, entendeu?
 Mas tem isso acontecendo, só para te dar exemplos de coisas que a gente pode estar ofertando, que a gente está gravando e falando aí, e ela pode colocar isso como exemplo depois, mas que ele sugestões de bautas e tal. É um teste muito excelente porque a gente está pensando como parte do módulo desse transcriber, de botar um companion para acompanhar o nosso trabalho e pegar o que a gente fala.
 mesmo que nem se acabou de falar, a gente vai conseguir usar isso como o teste para saber se LLM realmente vai dar atenção para isso que você acabou de falar. Então, vamos ver se está ligeirar mesmo. É isso mesmo. Mas aí é isso, é criar uma conversa assim, quando ela que depois ela vai lá, vai ter que tirar um contexto daquilo. Acho que é isso, assim. E aí, só, né, por fim, mas não menos importante, a gente falou sobre tudo isso, mas assim, acho que também o pulo do gato dessa parada toda, é que aí é isso.
 A gente usa também, lembrei aí e tudo mais, é para fazer uma análise de contexto com o que o cara faz, porque não é só uma transcrição, tem aquele lance que a gente falou lá no começo, que é de uma análise de contexto, palavras que o cara usa, redes que ele usa, uns de cada ciclinho. Isso aí é o saldo pra Nitongue que eu mencionei, que tem algumas abordagens técnicas possíveis diferentes, a gente precisa aprofundar, ver custo e trabalho, que de fato dá para fazer, mais para poder...
 pegar isso e aplicar só com esse treinamento. O espetulho, todo o material do cara, porque vai saber como ele fala, os trejeitos, tudo. Então, beleza. E isso pode estar dentro daquela caixinha que a gente colocou já de coisas extras. Que é um editor com já o bagulho decupado, que é já a voz dublada e transcrita e tudo mais. E essa outra parte pode ser...
 a gente está dentro da saca, porque demanda bastante processamento e tal, e fala, você quer fazer, beleza, a gente vai fazer com você e tá, vai pôr tais informações, tais, vai gerar x dados para a gente poder trabalhar em cima, e pode deixar esse robôzinho girando lá por um mês, vai custar 1, 2, 10, 20, 50, 100, entendeu? E beleza, acho que é legal a gente mostrar isso para o cara, mas a gente tem que chegar com esse problema resolvido, ó, você conseguiu fazer uma gole aqui com 80% e a gente está indo para 95, sei lá.
 E com uma parada ainda mais melhorada. Tem uns vices de linguagem, tem umas outras coisas que já galeram em Caio pelo que eu ouvi. Entendeu? É... E dentro desse estrelato ainda é falar de uma outra coisa aí. Não é isso, acho. E aí ver com o que é que custa esse negócio, como que a gente faz, porque a gente divide o projeto em duas camadas. Uma pra atuar diretamente o que ele tá fazendo e a outra, como...
 o treinamento e criação de uma empresa maior de traduções e contextos e tudo mais com uma finalidade nesse sentido. Para o creator, mano isso aí por isso isso fica bom, tá ligado? Quanto mais faz mais vai ficando bom, né? E começar a cair nos creators grande que quer fazer tipo Mr. Beast, sabe? Sabe quem é? Os caras tem conteúdo dublado em 96 línguas, tá ligado? Tipo, como faz isso sem ter a grande daquele tempo?
 Então, entendeu? Aí é a ideia de poder habilitar várias criaturas grandes de fazer um bagulho desses, para ser interessantes. Aí, até tenho uma galera aí que eu conheço, que eu consigo até misturar depois, para fazer umas conversas assim, galera. Imagina, também conheço várias pessoas. É isso que eu estou falando, tem um network interessante para abordar, é algo a pensar como o produto mesmo para a gente investir em. Certo. E aí, uma última pergunta, que era o que eu estava pensando aqui, é se esqueci, voltei, esqueci, voltei, esqueci e voltei.
 Bom, é... Por que ele falou que ele está tentando fazer isso? É uma coisa intrínuosa aqui, né? Então, jogando... Lê na fogueira. E ele está tentando fazer... A galera lá do estúdio dele que produz os vídeos falou que está tentando fazer, que caga a sangue lá para transcrever os bagôs e tal. Mas está tudo na verdade transcrito de YouTube automático. E não... Teoricamente os caras não tiveram trabalho, ele de elechendagem de nada. É, tudo automático. Então, e por que...
 bem relacionado que a gente não... vai ver noção desses vídeos do youtube não, mas pode ser só um tipo esse tempo que a gente pegou pode ser tipo, o boarro a casa não tem pode ter um vídeo de semana retrasada que tem, tá ligado? A gente só não pegou 6, 7, nenhum de períodos diferentes de um ano pra cá eu acho que nenhum tem então é que se tá caro o bagulho pra eles vocês entendo como se mexeram? tem um tipo feito um um de teste viu que dava mas custava caro e não fizer é, vamos ver
 Porque aqui esse que eles me mandaram, eu achei que ele ia ter esse rupturo. Porque aqui eles tem um exemplo do AI que geraram, que tem erros, e do humano que gerou também, que está mais correto, digamos. Então os dois exemplos ali, eu não sei se é um ademo do site lá desse assembly. Não, assembly não. Amber? Amber, você tem que ter uma coisa importante a gente frisar aqui como filters. Ó, a AI, vamos ver se você está ligeira. Volta lá para a caixinha de coisas importantes para entregar nesse...
 A gente precisa se der para fazer uma ajuda de pre-cut mesmo, de edição. Não sei se dá para fazer isso já, se demanda muita máquina, mas isso é foda. A pergunta que acabo de fazer se eles usam na legendagem, não sei o que, é porque eu falei que eles estavam gastando tempo, né? Que eles gastam tempo? Eles gastam tempo na edição, tá ligado?
 Então, já está muito tempo na edição. Tem um negócio aí. E edição é foda, mano, é chato mesmo, hein, mano. E os caras não fazem só isso, eu acho, entendeu? Eu tenho uma teoria baseada na experiência que a gente mesmo tem tido, por exemplo. Conversa com 10 dev, 8, está totalmente por fora do bagulho EI desses 8, 7 são contos. Que tipo tem medo de perder.
 emprego, pode ser que a galera esteja na surdina de não querer inovar demais para não perder o trampo. Se ele tem uma equipe funcionário, é uma teoria. Alguém vai conseguir uma. Óbvio. Mas mesmo assim, você entrar na mente da pessoa e fazer ela entender que o mundo está mudando e que ela só precisa se adaptar naquilo que dá todo mundo a ficar sem emprego, tem um caminho aí. O que você acha? Cara, não, eu...
 Eu acho que o Rafa falou do tempo que a galera está perdendo, pode ser edição mesmo. Por isso que eu tinha comentado justamente a ideia do... O editor, né? O editor, mas eu... O cara, pode ser isso mesmo. Pode ser que a galera está com medo e não está procurando solução por causa disso. Ou eles acharam e estão matando tempo. Já fazem uma coisa, estão matando tempo. Eu fiz um vídeo muitos meses atrás de uma ferramenta que o cara estava usando, justamente um EI para fazer um...
 Precante, ele tava cortando um podcast no migrânio, o cara virou no vídeo assim e falou eu vou perder emprego, o bagulho tá fazendo sozinho, ai você tá na tela dele, o bagulho tipo selecionando os bagulhos. Deve ter alguma coisa que a gente possa partir de algum lugar eu imagino. Já que não seja do zero né. É, dá uma ajudinha nesse lance assim tipo, às vezes até uns negócios de zona de calor, não sei, não sei como é que faz isso de verdade. Pra editar. Eu edito meus vídeos.
 aqui é uma trampa assim e eu tenho que lembrar o que eu fiz durante o dia porque às vezes eu posso ter feito alguma cagada no vídeo e não cortei de ter estrolado ele rápido assim entendeu um saiu com uma fala no fundo e na verdade era para o vídeo sair sem som colocar um áudio por cima nossa verdade você tem que ligar em torno de um pressuposto que a gente investiria em uma plataforma dessa
 Os próprios vídeos diários podem servir como um modelo de treinamento da parada. Uma hora o bagulho começar a fazer sozinho. É muito linear o que você faz. É tipo acordei de manhã, olha aqui, de manhã hoje eu fiz isso, papapapa. Logão. Logão. Hoje eu nem filmei inclusive, tenho que voltar para casa e filmar alguma coisa. 4.43. É mesmo? Bom, agora imagina, você só tira os raw footage e se curva.
 Cospo e o bagulho noial lá ele vai fazer pra tudo. Alguma coisa a gente já consegue partir. Em 4, 3 que eu já vi, um que a partir de podcast ele gera shortzinho com aquelas legenas que se mexem na tela pra engajar a galera e não sei o que, lembro que eu vi isso aí, sei lá, mesmo passado. Não sei o que assim, então que tem, tem. Que, o quão bom é, não sei, mas deve ser mais...
 mais rápido que o mundo fazendo. O GoPro fez o que edita. Faz um futebol de tipo... Faz um monte de material crô, sei lá, ser surfando, skate. Esporte radical, correndo, ele faz um opário. De acordo com coisas que ele tá vendo ali na filmagem, sabe? Mentos, então você tá surfando, tão te filmando, tá vendo logo a água se mexer e tal, tá acompanhando ali.
 Tem essas fitas. Bom, vamos fazer a transcrição e o que sai? Minijá. Cala, Cala, 44. Parando aqui. Precisamos minijá.


MEET 2: 

 Não, não, não, não, acho que está no Discord, estava procurando meus files aqui, não achei. Eu te mudei copy paste no disco aqui, só quero saber como é que era. Pois é. Pois é, papo. Aqui, achei já. Mais baixo do que o esperado. Acrição com o message, tá, beleza, eu tenho aqui, eu vou copiar com o Laisso aqui no noxio para você se ver.

 E aí a gente pode começar a partir daí? Deixa eu dar uma atividade. Pede pra ele aí. Cara, se vocês quiserem já tipo colocar, eu sei que tá meio que escrito aí, mas assim, de bate pronto fácil, né? O que precisa ser feito é trabalhar numa aplicação de transcrição e legendagem. Esse é o ponto 1. Aí o ponto 2 é...
 e traduzir. Traduzir parada por outras línguas. Isso no final desse documento aí tem exatamente isso. As principais demandas ali. Aí eu tô... aí eu tô maior agora. Aí te vi louco o que é que eu organizado. Tu salvou? Ele jogou embaixo e veio de substituir. Ah, beleza. Eu vou apagar de cima então.
 O que maravilha, eu peguei o bagulho, você me copiou e colou no WhatsApp, e o bagulho virou um documento formatado. Mas isso é o Notion, não é? É, é o Notion. Mas aí ele faz para você? Faz, tem OER aqui dentro. Então, mas aí você precisa falar que você quer isso, ele já fala. Não, não, não, ele copiou e colou, apertei espaço aqui, eu falei, ah, formata para mim. Fodido, fodido. E é bom, vamos lá. Ele está usando o Emberscript hoje.
 Sim, né? A gente deu até uma olhada como é que era, achamos caríssimo inclusive, né? Isso, se eu não me engano, é 1,60 por minuto para um humano transcrever e 100% de precisão. E não sei quantos centavos de dólar também para um robô escrever com 85% de precisão. E aí, partindo disso, o que eu acho é que a gente consegue, com o experimento que a gente tem hoje, gerar uma transcrição com 100% de precisão.
 uns 95% de precisão para mais usando o AI. Isso diretaço. No sentido de que só botar na ferramenta para transcrever e colocar no padrão ali. Nem no padrão, só para pegar o que está falado. Por exemplo, agora mostra ali o que tu transcreveu, o Jeff, sabe? Eu fiz um teste, gerando isso aí, tem algumas coisas que ele... Aí no larga até pegou o certo...
 No minuto 1 ele fala como a gente não tem cut-ness. Ele fala isso. Como a gente não tem cut-ness, no modelo Small eu não consigo pegar essa frase. Legal. Aí ele já tem uns detalhes assim, mas o que eu tinha feito era pegar o que foi dito, a transcrição, colocada na AI para ela falar assim e perguntar para ela, e ela dar uma olhada baseada no contexto.
 pode vir uma coisa meio errada na transcrição, mas não acontece, não pega. E ela já fez uns ajustes legal, então com mais tempo de para ajustes a gente consegue deixar uns, sei lá, uns 98% para só o humano dar uma revisada no final. Isso partindo da transcrição. A partir de deixar para informatos de legenda é bem facinho. A gente já tem como deixar nesse formato aí que tá meio tosco ainda de só dizer a cara 30 segundos. Mas...
 com um pouquinho de ajustes, a gente consegue deixar exatamente cada fala no tempo certo e já no formato, sei lá, SRT pro YouTube, então essas duas coisas dá pra fazer bem tranquilo assim. É uma coisa legal, já pensado ali, do ponto de vista de transcrição, não sei se já tá pensando aqui, mas enfim... durante o texto, né, durante a fala, na verdade, durante o vídeo e tal, enfim... vão ter coisas que vão estar erradas mesmo, sabe? Tipo que a pessoa fala e se corrige. É...
 Nessa hora, essa transcrição não precisa se corrigir, entendeu? Então, se o negócio já está fazendo uma análise de contexto, a coisa toda, ela pode corrigir, inclusive, tipo, essas partes que estão erradas. Sim, isso aí já tem duas perguntas. Seria só naquele quando a pessoa dá aquela gaguejada, ou quando ela fala uma palavra errada depois se corrige, mas também quando ela... Quando tem essas interjeições que ficam tênticas...
 o tempo que tal coisa, justamente que tudo daria pra gente tirar. É justamente isso, do ponto de vista de execução do trampo, porque o vídeo não tem roteiro, entendeu? O vídeo que a gente vai fazer essa transcrição, ele não é roteirizado. Então é justamente esse um dos trabalhos, que é roteirizar.
 Tá ligado? Então o vídeo é tipo no FreeFlow. Então o cara responde perguntas, né, durante os vídeos. E ele responde com base nos conhecimentos dele. Ele não abre um Google ou alguma coisa ali para pesquisar e falar, né. E antes o vídeo ir para o área e também não pegou a pergunta antes para elaborar em cima e fazer uma pesquisa. E aí na hora do vídeo ele já faz um negócio que tipo está
 pouco roteirizado, não, é justamente isso. Então, muitos desafios deles também, quando a gente falou daqueles ansios de transformar em roteiro, é por conta disso. Transformar em roteiro vai ajudar a gente depois... Tipo, ajuda a gente a fazer a transcrição de uma maneira mais contextualizada e que fique melhor nessa transcrição. A gente consegue fazer um roteiro, e na hora que a gente conseguir traduzir isso para outras línguas, ajuda também nessa parte de roteiro, de ter um negócio...
 utilizado, que não é uma coisa que é uma fala livre, com também uma contextualização na tradução, por um negócio que não fica aquele tradução literal. Hoje o próprio Google Transmit já usa contexto para traduzir. Então é mais só colocando isso verbalizando aqui o que eu estou pensando, já pensando na aplicação acontecendo. Você sabe, né? Ah, então meio lanseguido... Mas isso é importante assim, desculpa de cortar.
 Mas só reforçar, para a gente não esquecer, que esse trampo é um trampo de transcrição, mas na verdade é como se fosse uma IP de transcrição e roteirização. Transcrição e roteirização. E faz assim, se a gente quiser se chamar... A gente... Eu tinha pensado já nesse... Qualquer estratégia que a gente vai falar, porque acho que esse é um ponto importante de se abordar.
 imaginando um mundo onde tudo seria possível. Como que a gente poderia usar os dados dele para poder gerar esses roteiros? Qualquer... Algumas estratégias possíveis. Ó, os sugestes. Beleza, faz o quê? Tipo assim, é... Eu tenho como extrair conteúdo do vídeo, juntar, transformar todos os vídeos dele em texto e alimentar um bagulho.
 mas se a gente conseguir definir uma estratégia no dentro de um escopo mais fechado, primeiro quanto mais simples, a estratégia é melhor, e isso também vai dar uma visão do que precisa ter feito para atingir o resultado. Eu acho que a gente pode simplificar bastante. Todas essas coisas que dá para fazer com esse material que vai ser decupado e que a gente vai ser alimentado numa base de dados, enfim, vai ser aquela nossa matrix novenzinha de um arquivo 1, tá ligado?
 O que a gente vai fazer depois com aquilo, a gente pode depois estudar. Acho que talvez a gente possa fazer primeiro e talvez esse possa ser um pulo do gato, tanto para mandar para ele e fazer um projeto para ele, mas também depois pegar esse projeto se for o caso e plugar em qualquer outra coisa que é uma ferramenta de roteirização. Tive uma ideia. Tive uma ideia. Tive só uma dúvida antes disso. O que ele vai querer usar, eu só fiquei na dúvida inclusive outro dia, é só baseado nos vídeos que estão por aqui.
 pronto ou ele vai querer fazer alguma coisa no vídeo cru antes de dar uns cortezinhos assim porque funciona da mesma forma mas ele poderia por exemplo transcrever um vídeo inteiro cru e a partir do vídeo cru eles já conseguem ver pelas falas para não precisar assistir todo vídeo e selecionar melhor os momentos que vão ser cortados ali depois é isso também uma coisa que pode auxiliar na edição do vídeo para que
 quem for fazer, mas porque esse pode fazer só dos vídeos que estão pronto, a gente inclusive poderia já começar a rodar tudo em cima dos que ele já tem e mostrar alguma coisa em cima disso, só base de dados já tem, só precisa trabalhar em cima dela com os vídeos que já tem também. Eu acho legal, a gente pegar um vídeo que já existe, transcrever ele e ver como é que vai cuspir esse documento, então eles já conhecem esse vídeo. Tá aqui, ele já é o primeiro sample, agora o que a gente vai fazer com isso?
 Isso, a gente precisa transformar isso num roteiro, sabe? Então, mas o que foi assim? Foi fecha. Por que roteiro sendo que tipo isso aqui já é uma transcrição de vídeo que já foi feito, o DeFord foi roteirizado? Porque isso, na verdade, é o jeito que o negócio vai pensar e com os peças e informações, aí depois você escolhe como é que você quer. Então isso que ele tá falando de repente, que tem um pré-cut? Não, tá, e é outra coisa, é outra parada, não tem a ver com a autorização, não tem a ver com... Não, mas olha só, isso daí que a gente fez, tem dois modelos, o modelo que tá com o TimeStand,
 O modelo 100 foi pensado justamente para que fica mais fácil para ir trabalhar em cima, porque a partir dela dá para criar pontos mais interessantes, roteiro, tudo partido desse base que seria a transcrição crua. Então a partir daí a gente pode fazer um monte de coisa, é só questão de trabalhar o que a gente quer fazer, basear nos dados daquele vídeo em si. Mas isso é um vídeo que já está...
 Tá pronto, na minha cabeça já tá autorizado, porque já foi pro ar, entendeu? Então, ainda não entendia essa parte de roteirização quando o vídeo já tá pronto. Beleza. Vou falar o que eu vejo, a Thé também colocando um pouco do que eu conheço de produção de vídeo. É interessante gerar, usar esse... não sei como ainda, né? Se vocês usarem o conteúdo para ajudar, ou gerar no
 para as pautas de repente ou ele trazer, imputar as pautas do interesse dele e a gente usar os dados que ele já tem para tentar acamar a ideia que ele colocou. Então, acho que é isso dentro do estratégico, só que é tipo, é predição, não tem exatamente... Então, mas isso são só sugestões para outros vídeos. A gente tem que entender que assim, o formato desse cara de gravar vídeos, tá ligado? Ele só liga a câmera e vai... Lembra que é um...
 um produtor de conteúdo específico, mas pelo que vocês já estão me falando aqui, minha cabeça também já está fritando e dá para dar isso para outras coisas. Então, por isso eu estou falando que esse negócio de roteirizar já é muito legal, porque parte da demanda dele, que a demanda dele é, é um free flow ali, eu não tenho uma pergunta, só que a gente tem uma necessidade de transformar esse free flow também num roteiro mais côntho, organizando mesmo. Então, assim, vamos imaginar que aquele vídeo
 Como que você enxerga a utilidade do roteiro reverso? A utilidade do roteiro reverso é que você vai conseguir ter um jeito daquilo que está organizado, sabe? E essa informação organizada você pode fazer várias coisas com ela. Justamente fazer as traduções depois, justamente depois pegar esse negócio e poder filtrar ele e fazer uma sugestão de novas,
 novos temas. A gente pode ir além, né? Criar shorts e afinas... Eu ia falar, quando eu estava falando que veio ideia de algo que dá para imediatamente fazer, inclusive pegar um sample de vídeo e gerar em cima, ele faz um vídeo giganteiro, escolha, até abrir aqui o Instagram dele para ver o tipo de vídeo que ele posta em stories, etc. Mas de repente, podia pegar trechos de falas fortes dentro de vídeos mais longos dele e falar sobre aquele assunto para gerar um short para o YouTube.
 para Instagram e etc. Por isso, então. Por isso, mas estava me perguntando qual é a necessidade de criar o roteiro. O roteiro é para isso. Então, assim, qual que é o lance do roteiro reverso? Na verdade, o lance do roteiro reverso é que você vai organizar as informações. Ah, o lance que ele falou de ter um precante, de tipo dentro desse monte de coisa, desse monte do vídeo que está lá, desse monte de fala, de repente já está. Quando você coloca isso no roteiro, você vai conseguir cortar.
 e saber onde que estão os pedaços que vai ser realmente o conteúdo do vídeo. Tá ligado? Nesse lance do pré de roteirizar, a gente já está pensando em uma ferramenta pré-vis no futuro também. E na hora que o cara gravou o vídeo, esse vídeo gravado realmente depois ele vai para um lugar, ele é editado e depois ele sobe no YouTube. É, rapitão, você está gravando isso aí?
 no YouTube e fora, não é um vlog, né? Então ele grava, os cara edita, tem esse trampo de fazer uma decupagem, importar uns negócios, mas não corta muito, porque não tem metedição, o cara não para de falar, porque nós estamos falando aqui, entendeu? Em cima de um raciocínio. E aí, o que acontece? Se a gente também cria o roteiro, faz a ferramenta decupar esse negócio e cuspir um roteiro, o que vai acontecer? A gente sabe que é um vídeo de tipo uma hora, dentro da dinâmica de vídeos que o cara...
 ou a gente pode depois em algum momento setar isso na plataforma também, a gente pode ter tipo 1, 2, 3, 4, 5 breaks entendeu? Depende do tamanho do vídeo quando o tamanho do vídeo dele às vezes vai ter, sei lá, 2 breaks, 3 breaks porque são perguntas diferentes e aí na hora que a gente cria o roteiro isso também já tá quebrado lá pra ele então eles são tudo informações que na verdade se jogou aquele vídeo bruto você pode até jogar o editado também mas aí o lance é você jogar o bruto você joga o bruto, pare, processa
 a porra toda. A ultima parte está falando mais o sentido de futuramente ele usar isso daí para pré-processar o vídeo antes da edição que ele sobe. Ele o César que deu essa ideia. É realmente interessante. A gente pode um passinho a mãe porque viável é só é mais bom de obra mas imagina que a gente tem essa transcrição o cara vai botar o vídeo ele a gente monta para ele uma forma de edição onde a edição vai mostrar a falinha ali já tá ligado.
 junto com o vídeo enquanto é de tanto. Então, pro editor é até mais fácil, porque ele vai ter exatamente o início e fim da fala. Tudo depende, você tem que dar um cheiro do quanto... Não, não, não, eu tô viajando aqui, só tô falando que existe a possibilidade. Sim, com certeza. E seria do caralho, porque já tá quebrada e tal. Tem umas ferramentas que, uma vez, eu já usei, tipo, de fazer decupagem de filme e tal. Esses caras fazem isso, assim, tem a... Tem um slider ali, você faz um... Tá como se...
 Se tivesse abrindo um Google Docs de film e aí você faz os comentários onde você quer nos trechos, no YouTube, mas acho que a gente não precisa ir nesse grau de edição, assim, até pode ir depois e ver preço e tal, mas... É, pode fazer um sampa manualmente de algumas coisas, assim, falar, mano, isso aqui a gente gerou um bagulho super rápido só para fazer uma demo, dá para melhorar mil vezes. Assim, o lance aqui nem... Ih, essa célula de criar hotel...
 isso pode estar em algum outro lugar e tal, que não necessariamente precisa ser só pra ele. Mas agora, pra resolver esse trabalho pra ele, acho que é legal a gente coletar, já ir escrevendo e colocar as possibilidades. Ah, pode ter um editor, né? A plataforma processou o vídeo, ela já vai decupar, já vai mostrar, já tá cortado, se quiser, você já coloca umas transições ali no meio, já faz o canva junto, aperta o play e já sobe no YouTube. Você nem precisa abrir o YouTube pra subir o vídeo, tá ligado?
 Tudo isso, sei lá, via browser. É possível, é possível. Vai gastar um... em boas máquinas lá do GFP, você vai gastar, tá? Mas até dá pra fazer. Uma ulância, eu acho, é na minha visão, tá? O que eu acho que a gente pode vir aqui, já com tudo isso que vocês estão falando, é... foca numa ferramenta que transforma tudo isso que tá falado em roteiro. E, Felipe, você já viu milhões de roteiros, você sabe como é que tá quebrada as minotagens de roteiro e tal.
 Então, é isso, tentar meio que quebrado nas minutagens de roteiro, das falas, com respiros e tudo mais. Pô, você já tem isso, ali um álbum. Aí, depois, quando você traduzir para uma outra língua, perfeito também, até se você precisar depois de umas coisas que a gente até conversou sobre, que é, ah, beleza, vou traduzir esse negócio, vou traduzir dublando. Só que eu vou contratar um native speaker para dublar esse negócio, para sair com o accento.
 só que aí porra eu preciso da voz do Cristian já vou jogar no modulador vai sair com a voz do Cristian aí você pega e coloca no e aí muito louco nvd da vida e a boquinha fica se mexendo com a boquinha da tradução que foi filmado do outro cara né? manda um trem mas vai... então, ai, inclusive quando surgiu esse negócio aí esse papel foi atrás
 Eu entrei numa seção como Crazy, que comecei a pesquisar, batia dentro. Eu achei uma parada. Os caras fazem... É só manomente, é tipo uma equipe que nem a gente, assim. Eles, ó, que a gente tem essa taxa, que é contratar nós sem mil dólares. De ficar mexendo a boquinha. É, né? Mas eles estão vendendo para Hollywood a solução para traduzir os filmes em todas as línguas, tá ligado? Mas aí imagina, você... Só modular a voz já é mais fácil.
 Então, não imagina quem joga mexer a boca, mas só vai dublar. Só vai dublar com a voz dele, perfeito. Então, e aí, o roteiro, quem vai ler o roteiro? Entendeu? Vai ter que ser alguém que é uma pessoa fluente. E ela vai ler que roteiro? Cadê o roteiro? Vai ter que fazer o roteiro não tá pronto. Não, é traduzido no vídeo original. Então, mas aí, um roteiro, para a pessoa poder ler. Entendeu? O que que é só poder ler? Mas o roteiro já não é a transcrição crua. Oi? E nesse caso, eu tipo, pensando que o...
 A pessoa que leria o roteiro seria o dublador da outra língua, no espaço de usazes. Esse roteiro, o gerão seria a transcrição com o tempo? O que é o gerão? O gerão é o que é? Ele transcomberte o texto? Não deu a sintese aqui? Tipo, você mandar um texto, ele fala numa língua e aí você só sintetiza a voz. Então, ele nem precisa do dublador? Não. Ele fala melhor, ele fala o roteiro.
 Eu estou falando tudo isso só porque qual é a necessidade do roteiro, entendeu? De estar estruturado em forma de roteiro. É só se ele for usar as informações, porque internamente é só registrar tudo. A maneira com que eu ia ler as coisas, estar no roteiro ou não estar no roteiro não faz diferença. Põe ali no texto do Christian e põe para ele ler um testinho aí. Eu só logaco isso aqui. Era assim. Eu focaria nesse lance de criação de roteiro e dali.
 todos os plugins possíveis que a gente pode fazer. É tipo assim, é uma bagulha de transcrição com roteirização. Aí entra essa vibe e dá brisa. Qual que é a ferramenta? A ferramenta faz isso. Ela faz uma transcrição. Ah, mas a transcrição já tem várias, né? Ela transcreve e roteiriza. Tá, mas o que ela faz com isso? Ela faz um monte de coisa. Por exemplo, eu posso legendar um vídeo com essa transcrição e com esse roteiro. Aqui é o seguinte, tem esse bagulho que é um instante voice clone.
 E ele não vai ganhar tanto em intonoção, mas é tipo uma parada que está para fazer uma demonstração com como seria mais ou menos o covarde dele. E aí ele tem esse Professional Voice Cloning que tem que pagar a mais. Deixa eu ver quanto custa. Professional Voice Cloning. Cloning, cloning, cloning. Instant Varsalon. Instant Varsalon.
 Eu estou de mais congresso, bora esse papel, eu vou escolher. Tem que ser isso. Escomem later this year, não tem. Eu não anso ainda, eles anunciaram um bagulho. Eu imagino que até se enrolar esse papo aí já vai ter. É só um testinho, só pra ver que vai sair na IP... Vou fazer o esquema agora. Na IP Google ou na IP Voice, né? Pega uma voz boa já, porque a gente... O usando no caso de uso que a gente queria, eu gostaria de transcrever para inglês.
 Por exemplo, nem precisa pegar a sample dele, só pega esse textinho aí dos primeiros 30 segundos, bota para converter para o Google ali, para o GPT e cola aí dentro para ver a voz. É basicamente isso que a gente faria. Como é que vai de novo? Ó, abre o transcription, copia qualquer linha aí. Então, pega ali, ó, então a arroguitura é no fundo.
 uma ruptura tecnológica. Mas só pegar aqui no começo, porque eu consigo até se encaixar fácil. Tudo foi. Valeu. Basicamente, você só vai mandar isso aí para alguém para converter para ti para inglês. GPT. Entendeu? E eu ia falar alguma coisa aqui para vocês e já passo logo lá, né? Esse. Pronto. Traduz família.
 para que inglês? é né a voz em inglês a default só tem que deixar os segundos depois, call no 11-11 e é isso aí só que imaginando que isso já viria transcrito em inglês né não teria esse passo aí que tem que fazer, é qualquer um que se tivesse feito bom
 Certo, acessando aqui. Deixa assim mesmo, né, monolingua, não sei. Essa aqui no caso é com uma voz que já tem, né? Não é? Estraduziu a tradução. Estraduziu a tradução. Valeu, valeu.
 Várias séries ali e esses que são em inglês especificamente eles tem umas entonações mais da hora não fica muito rebótico Esse que o Felipe pegou não sei como bom é mas a gente poderia usar uma coisa assim Ou algo ainda, nada em pé de a gente treinar a voz dele e aí vai ser ele falando inglês Isso pode ser, fica mais forte E isso aí é o potencial que eu vejo, se a gente prosse uma ferramenta essa aí eu ia preferir ir por esse lado A gente por perecer
 esse serviço não ia ficar tão bom em tonação mas o avó ficaria exatamente em volta Até lá O Briaroun
 As vezes não temos cutnesses, usamos a expressão subnesses. De verdade, essa é uma série mini que adereça em todas as variantes, o problema fundamental para a análise psicólica e também para a subjetividade, que são as divis... Traste essas divisões para a forma mais moderna do que o subjeto. Então é isso. Tralco aqui, mete um... Espanola.
 Ah, ah, mismo caro. ¿Para que habla español también? ¿No lo has cubierto? Como no tenemos cutnes, usamos la expresión subnes. De hecho, esta es una minisería que aborda en todas sus variantes. El problema fundamental para el psicoanálisis y también para la subjetividad. Esa es nuestra división subjetiva. Es una esplenicia. Entonces podríamos rastrear estas divisiones hasta la misma formación del.
 do jeito moderno. Então, isso é tudo. Parece meio americanizado. Que só é em inglês, esqueci de trocar. Mas ficou até bom para um bagulho. Era para sair um espanhol dos Estados Unidos. Entendeu? Um espanhol americano. Agora, seja está mais. Como não temos cutnes, usamos a expressão sobnes. De hecho, esta é uma miniserie que aborda em todas as suas variantes
 y tal para... ¿Cómo te está? O Antonio, Antonio, parece ser legal. Es legal, es muy legal. No tengo inglés, un español y así está. Mucho lenguado. Como no tenemos cadnes, usamos la expresión subnes. De hecho, esta es una miseria que aborda en todas sus variantes el problema fundamental para el psicoanálisis y también para la subjetividad, que son nuestras divisiones subjetivas. Entonces podríamos rastrear estas divisiones hasta la misma formación.
 de um sujeito moderno. Então, é isso tudo. Vamos colocar isso no vídeo? Ó. Bom, galera, é isso aí, meu. Acho que é foca nesse lance da ferramenta de roteiro, roteirização, óbvio que tem a transcrição, mas é isso. Eu acho que se a gente apresentar um negócio de roteirização e, óbvio, com esses features de transcrição, transcrição contextualizada, correção de possíveis vícios, essas coisas.
 coisa de linguagem é um é abre um vídeo dele pra gente ver junto aí e e e enfim e aí que os pisso como roteiro e a legenda do vídeo é isso que estão precisando agora é ligado aí depois é com esse aqui de quatro dias atrás depois é qualquer coisa aí a gente pode para gostar se ele quiser
 Ó, máxima da nossa querida Marília Mousque foi nossa baixista vocalista de todas as bandas que originaram a equipe produtora desse super canal YouTube, Moonie. Ele falou em ativo. Mas tocou ser elepe. E... Tem uns detalhes que eu peguei quando eu botei para traduzir que ele falou, por exemplo, bem estilo.
 E aí eu... Estilharam certo Só que daí a transcrição ficou como um styler mesmo E quando eu joguei para o GPT para dar ajustado para mim, ele ajustou para o styler É o tipo de coisinha que eu esperava que fosse ajudar depois Então, por isso que eu ia pegar uns 95% que dá para garantir Porque ela vai pegar contextualizado nesse tipo de casa É assim que é tipo a sotaque do carro, o jeito que ele fala, ok? Mas dá para ajustar
 Então, e outra, o que eu queria fazer é literalmente um negócio onde ele, na hora que dirá, ele já consegue literalmente copiar e colar ali o negócio pro YouTube já colocar legenda, tá ligado? Deixar no formatinho, redondinho pra ser usado no mínimo de esforço possível. Eu vou botar um prática aqui. Às vezes é porque não deu tempo. Às vezes não, tenho certeza. Vamos ver um vai, de 12 dias atrás, não, 12 dias atrás tem que ter já. Não, não, não, não, os caras estão frutidos.
 O vídeo que eu peguei é Rooftura, que é o mesmo desse que eles mandaram. Esse ali, ó, sabe, sabe, sabe. Um que tem um negócio verde no fundo. Esse aí é o que eu... A gente faz um trecho dele em três línguas, legidado, e aí manda de Dendo. Não tem. Então a gente pode fazer tudo do baseado nesse vídeo. Beleza, só tentar ver um vídeo de um ano atrás para ver se tem alegria.
 só que vocês vêem um arquivo também, eu acho que... Não, você é de um ano atrás até que é velho é tipo, isso, tá ligado? Não é só tudo bem, mas eles... A unha, a legendagem e provavelmente... Foi manual, né? Isso! De um ano atrás, não tem! Porra, que estranho! E potência sexual! Então, mano, ele não tem a parada... Vou botar mais um... Não, mas basicamente eu tenho de ser...
 Ta aqui no canal, Burnout. Também não, só gerador automaticamente. Ou seja, ele não paga o serviço que ele falou, que pesquisou pelo jeito. Ele tava atrás da solução, mas não contratou, entendeu? É, não, não, eles não contrataram, estão tentando. Tanto é que eles fizeram também umas coisas via de título via chat gp dele, estavam me falando que não gostou muito, também ficou meio... Ficou meio bosta, uma galera meio que reclamou, assim... É, isso aí.
 você só vai conseguir fazer mesmo com Farry Toney, porque você baixa todos os vídeos dele e vai gerar um padrão de como ele gera os títulos dele com a semandica por trás da balaça. É, e assim, outra coisa que eu acho que é legal a gente trabalhar é trabalhar com o pé no chão. Então, assim, se a gente já conseguir fazer essa parada que a gente está falando aqui, do roteiro, da transcrição, deixar a bala ali prontinho, poder traduzir nas línguas, mas assim, na verdade, posso usar trás. Recrição.
 bacana, com geração de legenda, já fodaona, contextualizado, essas coisas, né? O César falou, o Ben Styler. Pode colocar isso no apresentação que a gente manda pra ele. Olha, inclusive durante esse demo que a gente preparou, a gente pegou esses detalhezinhos, o próprio E.A. já corrigiu pra ele saber que a bagaça está acontecendo. É isso aí, é isso aí, beleza.
 o pacote fala ó, tá aqui e custa tanto, entendeu? tem que chegar assim, tá aqui e custa tanto cara, pula atenção, quero, tá ligado? vou contratar essa porra aí, tipo um subscription, tá ligado? 
 === SPLIT ===
 às vezes de um bagulho que a gente fez, não é dele a gente vai fazer nosso, entendeu? e ele é o beta, e deixa rodando eu não sei quanto custa, entendeu? mas vai custar a X, faz o benchmark com aquele lá aqui vocês falaram que custa o cara pra caralho e ele também falou que custa o cara pra caralho
 isso que eles não contratam, eles usaram uma coisa meio free, né? Mas é isso, o canal gera um dinheiro, né? Tem um número interessante de visualizações ali e eles fazem um reninho aí, aconteceram muita coisa, mas tem um negócio aí, entendeu? Tem muito vídeo, né? Vê quantos vídeos tem aí? 638. Tá ligado? Tá longa, tá ligado uma coisa na coisa. Mão Lancia, até porque eles querem fazer isso?
 para poder colocar em outras línguas, legendar em outras línguas e possivelmente dublar esse negócio. Então assim, vamos com calmo para de repente esse cara colocar, nem que seja alguma coisa um pinga pinga, paga um servidor de alguma coisa para fazer esses testes e a gente vai evoluindo nessa mesma ideia, de repente pode ir travando outras coisas, ó, conseguimos fazer, fizemos um bagulho foda aqui de tradução, amigão, fizemos uma tradução, custa mais tanto, ah, mas não quero pagar, não tem problema, a gente não para lela.
 Então vai, de repente, ativando isso, deixando a ferramenta disponível pra alguém comprar também. Ó, fiz aqui um bagulho aqui, mano, muda sua voz, caralho, você não quer comprar esse bagulho e tal, não sei o que. E aí, é isso. Vai aí de baguzinho. Pra algumas coisas básicas, já tá no nosso roadmap inclusive, né, tipo a porra de transcrição e tal, tal, tal. Mas tipo, umas paradas muito customizadas, assim, já começa a sair um pouco do que a gente tá vendo que vai fazer. Next, a não ser que...
 entre um cash flow ou respeito. Tipo assim, não é viável desenvolver uma solução para esse bagulho agora, negociando um modelo de subscript. Sempre uma grana na frente. Ou se a gente não resolveu investir uma grana para desenvolver o bagulho e fazer como você falou, ah beleza, vamos fazer a nossa plataforma. Mas você tem que ter um gasto que você não não sai. Pera lá. Beleza. Ele vai ter que bancar de alguma forma, mas a gente fala pra ele... Com direto e diretamente. Vocês ele entram como...
 pensando é. O dinheiro que você inventou para fazer a plataforma, a plataforma é dele também. Então, eu estava pensando no modelo que, de repente, essa, esses vídeos ajudassem a pagar esse negócio para dar essa função para ele, para ele gerar mais grana com esses vídeos e assim sucessivamente, entendeu? Inclusive, na sedância de tradução de línguas e tal. Mas a gente pode chegar numa outra forma. Só para você saber também.
 Tem uma quantidade, imagina que a gente já desenvolveu o bagulho, baixou a mão, todo o vídeo dele, mandamos pro AI, o AI conhece o cara do avesso já. E aí, pra começar a gerar coisa em cima disso. Ah, vamos legendar todos os 638 vídeos, vamos gerar toda dublagem em inglês e espanhol pra todos os 638, se não vai sair barato, já pego. Então, tem o custo operacional, tipo assim, tem o custo de desenvolver a tech, tem o custo de operar, aliza.
 que aí precisa ser... Mas aí a gente vende a ideia pro cara e às vezes vende pra ele ser só... Dá pra vender com geração. Dá pra vender a geração, inclusive. Tipo, eu não vejo talvez um modelo de subscription pra esse caso específico como envolve o uso de várias APIs e... áudio e texto, e GPD, e o caralho. E tipo, olha, pra fazer um vídeo assim, tipo, o bagulho custa...
 tanto o minuto do vídeo, para ele saber o custo operacional por trás da bagaça, e a gente desenvolveu um modelo de negócio em cima disso. Você é um cara que dá para a gente conversar a mesa aberta? Tá, porque isso, assim ó, o dinheiro para fazer essas coisas, poderia vir desses vídeos, mas... tipo cobrando dele. Do ponto de vista se a gente coloca ele lá dentro, e ele vira um partner mesmo, ele vira um...
 É um apoiador, um socio do produto e tudo mais. Aí a gente consegue pegar, aí tem que ver o folego dele, mas a gente pega outros dinheiro e usa ele próprio. E usa ele como beta-testing, exatamente. Ele tem material suficiente para ser um dos melhores tipos de beta-testing que a gente pode ter para esse tipo de solução. E aí o cara tem um livro, palestra, aí dá para começar a usar isso. E usar os outros para se trazer. Dá pra fazer bastante cuidado.
 Tem muito, tem muito coisa ali mesmo. Então, mas vamos lá, próximos passos. Desenvolver ou pensar como desenvolver ou o que precisa ser feito para desenvolver o negócio que vai fazer uma transcrição e uma roteirização de um vídeo, que ainda não foi para o YouTube, mas é de um vídeo de repente um free flow. Você vê, esse último que se abriu ali e tal, ele tinha até alguma coisa de roteiro ali, chamou uma participação especial e tudo mais, mas ainda é que os vídeos...
 Não tem não isso, inclusive aquele que vocês estão trabalhando lá, qual que é o vídeo? É ruptura, só para ir aqui lá porque eram mesmo que eles usaram de exemplo que foi mandado. Os homenamam o vídeo aqui. Lembra, olha, tá rolando uma captura aí, pá... É uma produçãozinha. Acho que é bem produzido. Isso aí é uma cena da série pelo que eu entendi. Esse cenário também é cenário da série, cara. Dá hora.
 tem uma série que chama Roptuz. Isso, ele tá falando sobre isso aí. É esse vídeo que eles usaram no exemplo e botaram trecho, não tem. Tem um mil e oitenta premium agora que eu fiquei. Esse é o seu sábio da Ressentadecidente, né? Mano, eu comecei a ler a transcrição do vídeo e me querer dizer pelo assunto, peraí. O cara era bom, faz uma análise boa. Então, aí que tá o polo do gato?
 esse cara é muito cabeçuda. Pra galera, cabeçuda, entendeu? Tipo assim, pra tentar dar um exemplo meio tosco aqui pra fazer essa análise assim, deixa eu pensar aqui que eu consigo trazer de exemplo meio de Deus, perfeito? É... Pô, é difícil falar algum exemplo assim, mas tenta comparar um site de fofoca, tá ligado? Com um site...
 de cinema, um IMDB da vida, sei lá, tá ligado? Os dois vão falar sobre cinema, sei lá, o lançamento do Veloso e Furiosos 10, sei lá, entendeu? Um vai fazer uma análise do tipo assim, sei lá, Vin Diesel, os músculos, o Tá Velho, o Barrigudo, né? E o outro vai falar, puto, o filme tá fechando a saga, não sei o quê, é uma análise mais técnica, tá ligado? Inevitávelmente, o de Fofoca vai ter mais visualização do que o...
 esse brother é um pouco isso, então assim, ele é psicanalista, ele faz análise, muita coisa e esse canal me proponho muito com análise de questões sobre psicanalises. Hoje em dia ele é colonista no wall também, então ele escreve no wall sobre cotidiano através de psicanalises, mas muito sobre séries e coisas que estão acontecendo, enfim, uma série de coisas nesse sentido, tá ligado? Só que é isso, ele não consegue ter um alcance, tá?
 e o seu bicho dele também, que você está muito mais na galera acadêmica, na galera que quer escutar de repente uma coisa mais cabeçuda, do que da galera mais normal, só que às vezes está interessado, tipo o César. O César era psicanalista? Não. Não, não. Não de eu sei, não. É que eu de eu sei. E o cara está fazendo uma análise aqui, ele tem os pontos dele, ele é cabeçudo, ele faz essa análise que não é uma análise...
 cinematográfica da parada, ele faz uma análise psicanalítica da parada, entendeu? E isso também traz coisas interessantes e tal para você estar consumindo. E que hoje em dia tem até uma vertente que acaba consumindo mais. Então a ideia toda dessa coisa é como que também faz chegar para mais gente esses conteúdos. Eu tive uma ideia enquanto você estava falando de novo. Acho que eu tinha comentado isso e o assunto ressurgiu agora. A gente meteu o bote para fazer uma análise de sentimentos das coisas tóxicas do Twitter e Traseão.
 é uma pele fala sobre o que estava viralizado, tá ligado? Ele fala sobre as distorções da... Então, esse é o lance que a gente estava... É onde a gente está aqui na conversa. E é justamente de alguma forma também poder alimentar ele sobre coisas que estão viralizando e tal, para fazer uma análise em cima. Ele já faz um pouco isso. Mas talvez seja... É, é baseado em tudo que...
 O cara já faz, o que eu vejo de vantagem é a gente usar isso aí como porta de entrada para ele conhecer, mas a gente tem muito mais para oferecer para ele que ele nem sabe, a gente não sabe também. Porque a pouco ele vai fazer uma pergunta, dá para fazer tal coisa e aí é dois palitos para fazer a parada. O que é o outro? Então é supervário. Quanto mais gente de ramo diferente começa a ver essas coisas de AI, mais potencial vai ter toda a solução. É, e não é isso. É, e não é isso.
 interessante assim se vingou alguma coisa porque o cara é do metiê assim entendeu o metiêzinho uma galera uns cabeçudão de grana que segue ele né esses caras que a gente quer que é eu vejo que o dinheiro desse business aí não tá no usuário final que é o que é o paciente dele os pacientes dele eu sou nada ele nem sabe seu Paulo não falou
 porque o meu dinheiro pra ele realmente não conta. É, realmente não é nada. Não conta, né? Ele ainda... Tipo, é indiferente eu pagar pra ele, não mexe no orçamento dele. Agora tem uns outros caras que me com certeza mexe. Hum. É, eu nem sei o que eu tô fazendo lá com ele, não sei como que o cara não me dispensou ainda. Não. E já tô tipo uns dez anos fazendo análise, acho que é meio por isso, talvez. Talvez seja diferente. É um lugar confortável pra todos os outros partes, né? É, é, é. Se você já conhece ele... Eu não fico enchendo essa coisa. Eu fico enchendo essa coisa.
 para às vezes cancelar no meio do rolê não ficou tipo com certeza deve estar um galá no laque deve estar pitinho né come assim que acera não pare pessoalmente quem paga meu parado a secretaria dele fala ai Rafael nossa desculpa deixa eu ver precisar cancelar e tal é a sua você quer remarcar para algum outro dia eu falo não sei se vai que vem a nós porque é mó dinheiro entendeu então quando pula para mim também sliced você
 Se eu faltar, eu tenho... Entendeu? Mas se ele não me paga, né? Então eu vou falar isso pra ele um dia. Se você faltar, você vai ter que me pagar. Acho que tem uma coisa aqui que... Faltou falar o acreditado sobre esse assunto? Poco. Ah? Transcrição e roteirização. É isso. Transforma o bagulho não naquela decupagem. A gente precisa de um roteiro. Acho que isso é o pulo do gato pra parar da toda, entendeu? É pegar uma conversa, tipo que nem a gente tá falando, se a gente tá falando, se a gente quiser...
 se transformar isso aqui num vídeo, a inteligência artificial ia falar assim não demorou, vou fazer um roteiro. Sabe aquelas brisas que os caras fizeram no começo do chat GPT? Até te mandei esses vídeos lá no começo, muito tempo atrás que os caras fizeram uma sketch pedindo para o chat GPT, tá ligado? E aí a sketch é uma fala assim, ah, os caras começam a zonar, você viu isso aqui? Tem uma inteligência artificial, ah, esse aqui é o... então fala qual que é a capital de
 Certo, ai, qual que é o capital do outro? Aí o outro, ai é tal, ai eles, ah pô, interessante, né? Ah, mas não faz muita coisa, mas pô, isso a gente pegasse e criasse uma sketch usando essa inteligência artificial, aí aparece lá, tipo como se fosse essa parte da linha já escrita pela própria inteligência artificial, que a sketch era aquilo que eles estavam gravando, tá ligado? É... Então a inteligência artificial se comportando do bom ponto de vista digital, ofertando...
 O interrúdo para a galera lá. Eu nem sei o que eu estava falando isso no começo. Mas era uma coisa importante. Do pun de vista de... Ah, é um negócio foco, né? Eu estou perguntando. Eu vou colocar em roteiro e a partir do roteiro dá para fazer mais parada. Vou transcrever isso que a gente falou agora ou se as vezes...
 Não, lembrei. Posso lançar nos canteiros? Eu coloquei o bagulho aqui, mando o arquivo e eu transcrevo aqui rapidamente. Tá, você compara aqui agora e não... Não, não, vamos terminar aqui. Termina aqui, a gente pode, que assim, o lance é... Por que que precisa fazer um roteiro, tá ligado? É porque o arquivo não vai ficar só uma decupagem crua. Se a gente roteirizar ele também dá um acabamento, tá ligado? Pra você poder ter esse arquivo de base. Então, o que eu tava falando aqui, se a gente quiser se transformar...
 Nosso papo aqui que a gente está tendo, num vídeo de YouTube que aí o negócio vai estar setado em transformar aquilo em um vídeo que você vai gravar ou já foi gravado. Na verdade, um vídeo já foi gravado, mas você pode gravar ele de novo se você quiser. Então, por exemplo, nesse caso do que a gente está aplicando é de um vídeo que já foi gravado. Mas essa ferramenta, se a gente quiser, a gente pode usar outras coisas para ter sites para virar em roteiros e gravar em vídeos produzidos.
 Então, acho que esse é o grande delas, de pegar alguma coisa para o estar, ter uma conversa ou alguma coisa aí, como você pode absorver isso e transformar no roteiro para alguma coisa que você pode produzir depois. No nosso caso, já vai estar produzida, a gente vai usar os ácites dessa transcrição para fazer legenda, traduções e, de repente, servir de roteiro para dublagem,
 E aí, como próximos passos, eu acho que é entender como é que isso funciona, viabilidade técnica, tempo, grana, o que que consegue fazer e segurar a onda do ponto de vista de desenvolvimento até aí, para essa entrega, sem traduzir nada, sem nada. Se quiser, acho que pode... Então, vamos nos demorar para usar o que eu já tenho de serviço contratar, por exemplo, esse taxi to speed que eu cozei aqui, tipo, eu pago, tem uns caras...
 Teste aqui, eu não consegui fazer um bagulho com aquela itonação da hora, mas eu consigo fazer um trechozinho de 10 segundos de ele ver o vídeo dele dublado. Então, assim, o que a gente pode fazer, e é isso é ótimo. Não, não, eu acho que é ótimo pra gente ter de demo e aí falar, ó, o seu trampo, o que você precisa agora? Transcrição, legendagem. É a burgulha da sua legendagem, Paulo. Tá aqui. Tradução e legendagem. Pum, tá aqui.
 O que a gente pode fazer também? Dá para fazer a parte de dublagem, dá para fazer a parte de produção de conteúdo, dá para fazer a outra parte de insight sobre leitura, de sentimento de Twitter, algo assim, com tudo que está lá de psicanálise e cuspir algumas coisas de correlação, de coisas com coisas, tipo, nem mar, mandando fazer logo artificial com narcisismo, sei lá, entendeu?
 Mas tem isso acontecendo, só para te dar exemplos de coisas que a gente pode estar ofertando, que a gente está gravando e falando aí, e ela pode colocar isso como exemplo depois, mas que ele sugestões de bautas e tal. É um teste muito excelente porque a gente está pensando como parte do módulo desse transcriber, de botar um companion para acompanhar o nosso trabalho e pegar o que a gente fala.
 mesmo que nem se acabou de falar, a gente vai conseguir usar isso como o teste para saber se LLM realmente vai dar atenção para isso que você acabou de falar. Então, vamos ver se está ligeirar mesmo. É isso mesmo. Mas aí é isso, é criar uma conversa assim, quando ela que depois ela vai lá, vai ter que tirar um contexto daquilo. Acho que é isso, assim. E aí, só, né, por fim, mas não menos importante, a gente falou sobre tudo isso, mas assim, acho que também o pulo do gato dessa parada toda, é que aí é isso.
 A gente usa também, lembrei aí e tudo mais, é para fazer uma análise de contexto com o que o cara faz, porque não é só uma transcrição, tem aquele lance que a gente falou lá no começo, que é de uma análise de contexto, palavras que o cara usa, redes que ele usa, uns de cada ciclinho. Isso aí é o saldo pra Nitongue que eu mencionei, que tem algumas abordagens técnicas possíveis diferentes, a gente precisa aprofundar, ver custo e trabalho, que de fato dá para fazer, mais para poder...
 pegar isso e aplicar só com esse treinamento. O espetulho, todo o material do cara, porque vai saber como ele fala, os trejeitos, tudo. Então, beleza. E isso pode estar dentro daquela caixinha que a gente colocou já de coisas extras. Que é um editor com já o bagulho decupado, que é já a voz dublada e transcrita e tudo mais. E essa outra parte pode ser...
 a gente está dentro da saca, porque demanda bastante processamento e tal, e fala, você quer fazer, beleza, a gente vai fazer com você e tá, vai pôr tais informações, tais, vai gerar x dados para a gente poder trabalhar em cima, e pode deixar esse robôzinho girando lá por um mês, vai custar 1, 2, 10, 20, 50, 100, entendeu? E beleza, acho que é legal a gente mostrar isso para o cara, mas a gente tem que chegar com esse problema resolvido, ó, você conseguiu fazer uma gole aqui com 80% e a gente está indo para 95, sei lá.
 E com uma parada ainda mais melhorada. Tem uns vices de linguagem, tem umas outras coisas que já galeram em Caio pelo que eu ouvi. Entendeu? É... E dentro desse estrelato ainda é falar de uma outra coisa aí. Não é isso, acho. E aí ver com o que é que custa esse negócio, como que a gente faz, porque a gente divide o projeto em duas camadas. Uma pra atuar diretamente o que ele tá fazendo e a outra, como...
 o treinamento e criação de uma empresa maior de traduções e contextos e tudo mais com uma finalidade nesse sentido. Para o creator, mano isso aí por isso isso fica bom, tá ligado? Quanto mais faz mais vai ficando bom, né? E começar a cair nos creators grande que quer fazer tipo Mr. Beast, sabe? Sabe quem é? Os caras tem conteúdo dublado em 96 línguas, tá ligado? Tipo, como faz isso sem ter a grande daquele tempo?
 Então, entendeu? Aí é a ideia de poder habilitar várias criaturas grandes de fazer um bagulho desses, para ser interessantes. Aí, até tenho uma galera aí que eu conheço, que eu consigo até misturar depois, para fazer umas conversas assim, galera. Imagina, também conheço várias pessoas. É isso que eu estou falando, tem um network interessante para abordar, é algo a pensar como o produto mesmo para a gente investir em. Certo. E aí, uma última pergunta, que era o que eu estava pensando aqui, é se esqueci, voltei, esqueci, voltei, esqueci e voltei.
 Bom, é... Por que ele falou que ele está tentando fazer isso? É uma coisa intrínuosa aqui, né? Então, jogando... Lê na fogueira. E ele está tentando fazer... A galera lá do estúdio dele que produz os vídeos falou que está tentando fazer, que caga a sangue lá para transcrever os bagôs e tal. Mas está tudo na verdade transcrito de YouTube automático. E não... Teoricamente os caras não tiveram trabalho, ele de elechendagem de nada. É, tudo automático. Então, e por que...
 bem relacionado que a gente não... vai ver noção desses vídeos do youtube não, mas pode ser só um tipo esse tempo que a gente pegou pode ser tipo, o boarro a casa não tem pode ter um vídeo de semana retrasada que tem, tá ligado? A gente só não pegou 6, 7, nenhum de períodos diferentes de um ano pra cá eu acho que nenhum tem então é que se tá caro o bagulho pra eles vocês entendo como se mexeram? tem um tipo feito um um de teste viu que dava mas custava caro e não fizer é, vamos ver
 Porque aqui esse que eles me mandaram, eu achei que ele ia ter esse rupturo. Porque aqui eles tem um exemplo do AI que geraram, que tem erros, e do humano que gerou também, que está mais correto, digamos. Então os dois exemplos ali, eu não sei se é um ademo do site lá desse assembly. Não, assembly não. Amber? Amber, você tem que ter uma coisa importante a gente frisar aqui como filters. Ó, a AI, vamos ver se você está ligeira. Volta lá para a caixinha de coisas importantes para entregar nesse...
 A gente precisa se der para fazer uma ajuda de pre-cut mesmo, de edição. Não sei se dá para fazer isso já, se demanda muita máquina, mas isso é foda. A pergunta que acabo de fazer se eles usam na legendagem, não sei o que, é porque eu falei que eles estavam gastando tempo, né? Que eles gastam tempo? Eles gastam tempo na edição, tá ligado?
 Então, já está muito tempo na edição. Tem um negócio aí. E edição é foda, mano, é chato mesmo, hein, mano. E os caras não fazem só isso, eu acho, entendeu? Eu tenho uma teoria baseada na experiência que a gente mesmo tem tido, por exemplo. Conversa com 10 dev, 8, está totalmente por fora do bagulho EI desses 8, 7 são contos. Que tipo tem medo de perder.
 emprego, pode ser que a galera esteja na surdina de não querer inovar demais para não perder o trampo. Se ele tem uma equipe funcionário, é uma teoria. Alguém vai conseguir uma. Óbvio. Mas mesmo assim, você entrar na mente da pessoa e fazer ela entender que o mundo está mudando e que ela só precisa se adaptar naquilo que dá todo mundo a ficar sem emprego, tem um caminho aí. O que você acha? Cara, não, eu...
 Eu acho que o Rafa falou do tempo que a galera está perdendo, pode ser edição mesmo. Por isso que eu tinha comentado justamente a ideia do... O editor, né? O editor, mas eu... O cara, pode ser isso mesmo. Pode ser que a galera está com medo e não está procurando solução por causa disso. Ou eles acharam e estão matando tempo. Já fazem uma coisa, estão matando tempo. Eu fiz um vídeo muitos meses atrás de uma ferramenta que o cara estava usando, justamente um EI para fazer um...
 Precante, ele tava cortando um podcast no migrânio, o cara virou no vídeo assim e falou eu vou perder emprego, o bagulho tá fazendo sozinho, ai você tá na tela dele, o bagulho tipo selecionando os bagulhos. Deve ter alguma coisa que a gente possa partir de algum lugar eu imagino. Já que não seja do zero né. É, dá uma ajudinha nesse lance assim tipo, às vezes até uns negócios de zona de calor, não sei, não sei como é que faz isso de verdade. Pra editar. Eu edito meus vídeos.
 aqui é uma trampa assim e eu tenho que lembrar o que eu fiz durante o dia porque às vezes eu posso ter feito alguma cagada no vídeo e não cortei de ter estrolado ele rápido assim entendeu um saiu com uma fala no fundo e na verdade era para o vídeo sair sem som colocar um áudio por si nossa verdade você tem que ligar em torno porra tá um partindo de um pressuposto que a gente investiria numa plataforma dessa
 Os próprios vídeos diários podem servir como um modelo de treinamento da parada. Uma hora o bagulho começar a fazer sozinho. É muito linear o que você faz. É tipo acordei de manhã, olha aqui, de manhã hoje eu fiz isso, papapapa. Logão. Logão. Hoje eu nem filmei inclusive, tenho que voltar para casa e filmar alguma coisa. 4.43. É mesmo? Bom, agora imagina, você só tira os raw footage e se curva.
 Cospo e o bagulho noial lá ele vai fazer pra tudo. Alguma coisa a gente já consegue partir. Em 4, 3 que eu já vi, um que a partir de podcast ele gera shortzinho com aquelas legenas que se mexem na tela pra engajar a galera e não sei o que, lembro que eu vi isso aí, sei lá, mesmo passado. Não sei o que assim, então que tem, tem. Que, o quão bom é, não sei, mas deve ser mais...
 mais rápido que o mundo fazendo. O GoPro fez o que edita. Faz um futebol de tipo... Faz um monte de material crô, sei lá, ser surfando, skate. Esporte radical, correndo, ele faz um opário. De acordo com coisas que ele tá vendo ali na filmagem, sabe? Mentos, então você tá surfando, tão te filmando, tá vendo logo a água se mexer e tal, tá acompanhando ali.
 Tem essas fitas. Bom, vamos fazer a transcrição e o que sai? Minijá. Cala, Cala, 44. Parando aqui. Precisamos minijá.


MEET 3: 

Alright, guys, we'll start now. So we're gonna be installing everything together.
Just to make sure everything is going and running in the same clean slate.
But if we do that, let me just explain what sheet layer is so cheat layer is an Rpa suite of tools.
Well, most of our customers run their businesses through a combination of services and websites, so our chrome extensions is most used now, but we also had a beta for the desktop that worked across Mac windows and Linux we originally launched to solve the problem of building automations from end
to end, and simple language. Using Gpt. 3, the P. Does for that was during the pandemic.
My friends lost their jobs and businesses, and I was helping them build online businesses.
And so some of those ended up being successful, and so they started referring me out, and that quickly got over mellowing.
And I thought about maybe possible solutions of scaling up somehow, and it is also around the same time that I got early access to Gpt.
3, and so we figured. That may be because the things that I was building basically backends and websites and automating their social media automating their sales team it's kind of the same for each person.
I was helping with slightly different parameters and the interface that they were coming to me in was language.
So it seemed like we could use Gpd. 3 to solve it, but it not.
The first version of Gpd. 3. So around summer of 2021 is when we actually launched, and that first early version, because Gp. D.
3. The code generator required you to be a software engineer to really use it effectively.
We built no code tools around that to get our first customers, and it took us a year to solve the original problem and build something called Project Atlas.
But you can access on any website if you had alt ask or option. F.
And actually builds entire automations for you from end to end.
And simple language. Finally realizing that original vision.
So it's kind of exciting, however, in this demo and through these Demos, I'm gonna start with our no code tools just to show you and illustrate the difference.
And then we'll mostly spend time on project Atlas automations. Excuse me.
Okay, so we're to start. We're gonna make sure everyone installs a clean chrome profile together and make sure everyone is in a Google chrome browser.
And not another browser like Brave, because Chrome supports simulating human key presses.
And sending unlimited data to Google Sheets.
And if you can see here, we can just wanna make sure we're on the same version.
And Google Chrome.
And next, we're gonna create something called a clean chrome profile.
And this is useful because there are extensions like add blockers that prevent automations that prevent anything like that from happening.
And then so let's see, it allows us basically also, if you create a new chrome profile, it prevents it from interfering with your main browser so you can minimize it.
And if you have scheduled automations they'll run in the background.
So to create a new chrome profile.
Scroll all the way down to the bottom, and then click, add!
And then click, continue without an account. And then we're gonna call it cheat. Where?
And then done so. We created a new chrome profile, and then, now we are going to log into.com.
This will have none of the save passwords or anything.
So you guys will use the top form since you presumably already have accounts.
It's not gonna save your password, so you might have to remember it or copy and paste it from the other browser in chrome settings.
You. We can find the passwords from other browsers, and copy and paste it basically.
So while you're doing that, I'm gonna log in on the bottom form very slowly.
Once we're logged in we're in the dashboard.
I'm just gonna quickly highlight some of the features on the dashboard.
Well. Towards the end of the demo, I'll go over the new agents dashboard, which is exciting, and then under here you have the scheduler.
You can schedule unlimited automations to your browser.
We we're uniquely the only automation service that has webhooks directly to the browser, and a fault tolerant scheduling server that allows you to schedule unlimited automations without consuming any tasks and if your
browser is closed, it'll actually queue the the request and then run them again.
When your browser is open, and so you can set up things.
And like, yeah, obscure. Schedules as well, like the second day in February, or something.
And optionally you can schedule things in cheque cloud which is on our servers.
If you want to scale up operations to thousands of maybe scrapings per day, or lead generations per day, you perhaps maybe don't want to do that on your IP.
It would get blocked. We can set up service, and once you prototype it on your extension it will run in cheek that as well.
Okay, down here. You also have your history. When you have history of run automations, they'll show up here.
You can immediately run them again. So you don't lose them while you're discovering things. And I'm gonna switch over now to my browser.
And let me check the chat. Okay, cool. So at between each demo, I'm just gonna make sure everyone is still following along, and no one is stuck or anything.
I'll try to read this. I think this is like a general question, but I'll definitely make sure to answer this towards the end of the call, and also, if you have any personal questions that you wanna ask.
Hey, Darren, I see this question. Thanks. I'm trying to read it now.
Feel free to email me at rohan@cheatlere.com, and we can also even set up.
It's like, if it's a question that you don't want to share with.
With, with with other people and things like that. We can set up a one on one time on things cool, alright.
So first, we're gonna go over a automation that I personally went over with all the first cheat layer users.
When we first launched, and or I just wanna go to Amazon and search for greenies or whatever you want.
Greens are my dog's favorite toy, and so we taught this pattern when we first launched in cheat layer, because it's the most common pattern on the Internet.
If you have a search page and something a search page and a product page or search page and a profile page, it exists me in most websites like Amazon, ebay, zillow, airbnb, Craigslist appsumo product on cheat layer they kind of have
this kind of pattern everywhere, because it's useful to find things and stuff.
So we taught. This, however, I mentioned when we first launched.
We talked, using our no code tools because we built no code tools around.
Gpt, 3. Just help users build, actually use flavors.
And so if you click the puzzle piece icon in the top, right hand corner in chrome, you can click the cheat layer icon, to open our no code tools and close them, and then at the bottom you'll have the access to the website, layer the code layer the no code
layer, to build and run unlimited automations without consuming any tasks.
So if you click, add automation, you can get access to the no code editor, and then you drop into this drag and drop interface that allows you to visually build your automations.
So typically what I would recommend doing is highlighting the title.
Clicking, add to cheat, and then clicking.
Save data.
And you don't have to follow along with this, because actually, product Atlas now build this entire automation for us, anyway.
But the purpose of going through this is just to illustrate the difference and the striking value of project apples.
So finally, what I would do is maybe scrape to g sheets and using this drag and drop interface, you can kind of build these.
No code automations, and next I would go to sheets dot new and a new tab.
Copy, the URL when you click these nodes in the no code graph they highlight what they're automating in the background, but also on the right hand side.
They have options that pop up for each one so these are parameters for maybe sending data to Google sheets.
I'm gonna post paste the URL here and then hit, file, run, or control.
R hmm! Just to run this simple automation and scrape data to Google sheets for one product and then next, what I would do is I would save this with the file, save.
And I would go back to the search page and again, you don't have to follow along because Amazon product Atlas is about to build it for us, anyway.
So!
I mentioned again, if you ran out of task. So if you're out of task that things might not work, feel free to send me your email, drop me the email in the chat, or send me an email, at Rohana cheatlayer.com and I'll reset your task so you can do
all this stuff for even try it after the call on your own time.
But basically, you can now open project Atlas on any website by hitting alt task or option.
S. On Mac, and it gives you this chat interface that builds automations for you from end to end, and simple language.
And it's amazingly effective now, because it took us basically a year to solve this problem.
And the way we did it is we built a library to solve all the roadblocks and automation for things like sending data, opening tabs, simulating human key presses, and bypassing cross origin restrictions.
And we taught that library to Gpt. 4 and Chat gpt in the interface of language, and that allows us to basically enable users to access that same library.
Those building blocks in simple language basically rather than being a python developer or code, or to build and discover our plugins and extensions.
Users can discover everything that's possible in simple language. And so just to go over any an example, you can say things like, Okay, scrape the product prices and descriptions.
In new tabs.
Or the product. Titles and reviews, or the product prices, titles, and reviews, or whatever you want, you can say, and the more important thing is that it actually builds the automation live based on context and so what it's doing here is we supplied. It.
With the HTML of the website, plus our request and in order for that to work, we have to compress the HTML 95% using a proprietary method.
And then it gets it gets the point of what it has to do here, which which is that it needs to create a Google sheet and link us to all the sub pages to build the automation for the actual products.
These services and websites somehow. And so, in order to solve that problem, we'd also taught Chat Gbt the ability to break down difficult problems into manageable tasks, just like if people would need to.
And basically use organizational structure and hierarchy to solve them.
Yeah, in pieces. And so now that's building the same automation that I would have except it's doing some cool things.
So one of the cool things is that instead of me teaching you or it teaching you how to do it over 20 min, hey?
Actually just built it for us in a minute, including linking all the pages together and doing all the sub pages and scraping and even setting up the Google sheet and so that's that's exciting.
The other exciting thing is that it solves an interesting problem for automation where I'm gonna just stop this.
So I can talk about that. Talk about what it's doing.
Maybe I'll leave a few of these open we're up until maybe 4 months ago.
All other automation tools. Would typically break when the websites updated their designs or code.
And so what would happen is you would have to go back and rebuild the automation or redo it, or things like that.
This happens periodically. For most of websites, anyway, and some websites even update their code every time you refresh the page, making it almost impossible to automate.
So like Facebook, for example. So.
This is really exciting, because if you look closely you can see that it's using the selectors's live on the website.
And so it's building the automation live. And so, in order to solve this, maybe before 4 months ago, and Gpt.
4 was released. You would need a software engineer to actually build the automation, live every time you run it so it wasn't actually possible until now.
So that's kind of exciting, so makes it more robust, and you can do a few things.
So once you build this automation, you can click, save, prompt or save code.
There's 2 options there. It's gonna close these on me soon.
If you click, save prompt, you have the option of keeping this dynamism where naturally rebuilds the automation, live based on context.
If you click save code, it saves this output, and then you can run it unlimited times without consuming any tasks, because it's just a code.
It doesn't. We don't have to generate it again.
So the other way to run unlimited automation, so that consuming task is once you upgrade, you can go to the agents dashboard and enter your own enter your own Api keynote. So that was just added in the latest update, and that if you add your own if you
have access to Gpd. 4. You can add your Gp.
4 Api in opening AI, you can add your own Api key.
That's free. You can get access to that you can add your own Api key and run unlimited automations and agents without consuming any task on cheapware.
So a lot of users are doing that now. You still consume tasks and open AI.
But you get like some number like $18 or something free.
I think so, okay, so let me just go back to this.
So it builds the automation, and you can do this on any website.
This. This doesn't just work on Amazon.
It's just Amazon is a common thing. We teach.
It works on like ebay Craigslist, zillow Airbnb.
Any random website you build any blog or something like that, or users.
Ivan, discovering wild things that we didn't expect.
It was possible. So if you go back to the dashboard, and I know I know I said it.
Maybe tomorrow takes 20 min to normally build this automation and wear 20 min. Now.
But the point was to illustrate using the difference between building and manually, and project Atlas, building it for a Us.
Basically instantly. So if you go back to the dashboard, you can click, cheat codes and you can see how other users not technical users like Kristoff.
Yeah, are discovering these things and completely simple language. And these all have video tutorials.
And one click buttons to instantly run them, and some of these work on all websites like this Darkmoon thing, and these are things we didn't expect were possible.
I don't know. This was possible and users are discovering them in simple language, which is exciting.
So you can join our community of users discovering these things and helping us iterate and discover and grow the library together.
If you scroll down to the bottom of the Cheat codes page.
There's a discord. You can join you can see how other users are discovering these automations.
So, for example, a user wanted the ability to oh, yeah, this is the Ethi thing.
Before I go on. If you click, add any of these, they all have one click buttons to instantly run them.
And these are basically all the supported automations for project atmospheres.
This allows you to conserve tasks it project Atlas is not general. AI, so it won't do everything.
It's at the same state of all other language models.
Now, whereas the alignment problem hasn't been solved, so it requires some trial in error.
However, the trial and error process you can see in our discord is basically simple language.
So, for example, what I was just talking about, one of our users wanted the ability to rank all the tweets from a search from yesterday, and he tried something that sort of worked, but it only generated 3 tweets, and so we figured out well, you need to scroll to the bottom.
Of the page, and you can see this process on the discord.
And we added that sentence and that worked out 12 tweets.
Whoever we need 50. So what we said is alright scroll 5 times, get 50 tweets, and then sort them, and then actually works.
And you can see the phrase that we used to generate.
It is all simple language, just like that, and it you can see it's an iterative trial and error process like that.
So it's kind of cool, so you can help us discover things.
It works on any website product that has access to any Cdn that's hosted on the Internet any Javascript library like 3 jazz to make 3D games.
You can make 2D games as well. People have made like space shooter games and stuff like that.
Functional tools it has access to in any Api that it knows up up until 2021. So things like the salesforce Api knows and stuff like that which is notoriously hard to implement.
And it has access to our internal library, which allows it to bypass restrictions and automation.
So things like opening tab sending data simulating human key presses and the ability to execute arbitrary Javascript.
So the solution space is wide, and we don't even know what's possible.
Actually, so I'm sure many things are possible just through a string of phrases, to reach them, just because you can execute arbitrary Javascript.
So!
So that's exciting. So you can do that. Hmm!
Now I'm gonna go back to cheat layer, and we're gonna go over an automation.
Oh, there's 3 questions. Let me just make sure. Everyone.
No one has. Oh, yeah, I'll restore your credit for you.
Let me see!
Oh, yeah, if you have any questions, feel free, to drop them in the chat.
Any general questions if you just come up with an idea while we're going along just so you don't forget them, and I'll come back and answer them at the end of the at the end of the call.
But if you get stuck in the any of these Demos as well, let me know, and I'll try to come back and help you, and maybe redo things and stuff like that.
And then, yeah, send me your email if you can drop it in the chat, too.
Cause. I think these are all direct messages, and I'll reset your credits or I'll reset it at the end of the call.
If you send me at the end of the call and stuff like that.
Yeah. No. Worries. Okay, yeah, maybe. I'll do that now before we go on.
If anyone wants me to reset your credits, let me know, and I'll just do that right now real quick.
Okay.
One sec guys.
Seems to be a few people, so if anyone else once credits task, reset, I'm gonna add more than you normally get, feel free to drop your email in the chat.
And just to make sure you guys haven't a press task for what we're doing here, and you can do it after the call to if you don't have time to do it.
Now, that's fine. But or send me an email after the call, if you have, if you want to do it later, too.
That's fine!
Alright. We got a few people now. Cool. Alright, I'm gonna reset everyone now.
One. We're on number 104. Let's get.
Oh, I think so one deleted one of the messages, anyway.
There's a sky, I think. Did you send your email?
I can't find it anymore. Alright!
They go down the list. I'm out of 204 I'm gonna do 3 of 4, and sky.
I can't see your email anymore if you sent it.
So I would just drop it again and these, I think these are all direct messages, so it should be private.
So, okay.
Retro. Let's see, lowercase. R, okay, yeah.
Make sure.
I'm on now, Donovan. I just did Timmy and Brian and Darren. And now I'm on Donovan.
And should only take a minute.
And sky. Okay, yeah, I got that email. Now, okay.
There we go! Alright. Hey? Cool, alright, guys, let's get back to it.
So! Oh, while we're going through this, you might as experienced some issues where it just like oh, it might not respond, or something like that.
It's because we're actually hitting our opening eye. Api limit.
So we recently launched something called Agents which can quickly spin up 10 tabs in a minute.
And so our Gpz 4 rate limit is 200 per minute, and then so if we've released this to 500 so far that we are already reaching our rate limit, basically, okay, so but we've released a solution which actually mitigates the whole issue my version doesn't you might notice the while i'm running things nothing happens
to me. But some things like you guys might have issues because you have the old version.
So there's a new version called 6.9 point 0. It's an auto update.
You guys will get it. It'll work, and it should fix most of these issues and Twitter, especially the one we're going to do next does not work in the version you guys have.
So you might just have to watch the next one, but it'll work in the next auto update, and it works for me.
So it's so, okay. So the reason is because we're actually hitting our opening our rate limit.
So one of the things that's helping us as users can bring their own key.
Now, and we also solve some a lot of issues in the in the update.
That at least it's it doesn't just like not respond.
It actually continues requests and things like that. So it mitigates the issue.
And it just lower. Okay, so this automation should be immediately valuable to all businesses.
When you get the next update and it allows you to basically automate any brand on auto pilot.
You can do this on other social media, like Facebook, Facebook, groups, Twitter, Instagram, Wordpress.
But basically you can say, post a tweet about whatever your brand is.
Every day. At 10 Am. And it'll build the automation for you.
But if you also say things like, do it every day at 10 A.
M. Or do it every hour or every minute, or every third Friday in March.
It'll actually schedule it. Even those weird ones.
It'll schedule it for you, using our fault tolerance, scheduling server, and so it'll run it when your browser is open, and if your browser is closed it'll cue them to run it whenever you open it again and we'll use
gpd 4. To generate this content. So every time it runs it every day.
Now, if you just type that phrase in that's done, it's not gonna run it every day now, and you'll need the next update for this to work.
Though. Sorry, guys, but it'll use Gpd. 4 to generate new content constantly every day to grow your brand on autopilot.
And I'm not gonna let that post. But you can search.
Oh, it went, anyway.
And delete this. You can search hashtag, cheat, layer, twitter, to see everyone else's who has a free accounts is using to grow this, to grow their business basically.
And you can see the day like it stopped when we had the issue.
So it's coming back again next update. Oh, cool.
So got it. Okay, cool. So that should be live by the end of the today, probably by tomorrow.
It's Google's reviewing the update. Now, we published it.
I mean we published it to them already. So it takes about a day, or maybe a few days, sometimes so hopefully, by tomorrow's done. Okay?
So these are only the free users. Actually, once you upgrade, it removes the branding so we can't see all the paid users doing this.
Okay. And then I wanna go over another Twitter automation this one probably what doesn't work for you guys.
But this? No, this one works for all of everyone, actually.
So yeah, that that what is a monthly yeah, it won't do anything yet.
So the update is will be available probably later today or by tomorrow.
Yeah. But this one will work for everyone you can. This is so.
But however, before I go on to this next one, I wanna just go back to the dashboard to illustrate that when you say things like do it every day at 10 Am.
It'll actually schedule it, using the scheduler and you can remove it here.
So click from move if you don't want to do that, but leave it there because you've now just automated your brand on autopilot with that phrase, and so if you use your brand, if you said AI automation, I might remove it and try it again, okay, so
avoided, scheduled it. When the auto update happens, it'll actually work tomorrow automatically. So that's kind of cool.
I'm like, leave your browser open and see what happens.
That'd be exciting. So if he had all desk on any other tweet. So go to any other tweet.
This should work for everyone, actually.
You can say things like.
Generate a reply to the Tweet on this page.
And it builds the automation. But it does it in an interesting way.
So if you look closely, you can see that it actually knows that content of the Tweet while it's building the automation.
So if you say things like this page when you're building things, or this website, it gives it the content context of the web.
So it intelligently knows, how to build the automation rather than having to build something to figure out what the Tweet is, and then process that actually knows what it is.
So that saves you some time. It does it faster. It's more robust and actually builds like a.
It actually responds in like a meaningful way.
I'm not gonna post this because we've been responding to nose tweets every on boarding.
So he's probably gonna see? Think something's up.
But that wasn't a bad tweet that was pretty good, actually.
So if you guys did your tweets, you should have completely different results.
Actually, and this should work for you at home. And now that you've built the automation, though the other reason I went over this demo is to illustrate that you have these option now at the bottom to save the prompt to save the code, or submit the new cheat code, so if you click save
the save, the prompt. It saves this version up here, like I mentioned it, allows more dynamism and allows it to regenerate this automation every time it runs.
And this is useful for things like Facebook, which has constantly changing selectors.
If you click save code, it actually saves this one and so I'm just gonna go over that just to show it.
Show how it works. For this Twitter automation. I would actually do the save prompt.
So it does it for every new tweet for a different tweet.
But I'm just gonna just for illustrated purpose.
I'm just gonna save this. Okay.
So you can file, save, or control S. To save.
After click save code. And now it's going to be in your library.
Once it's in your library. You have the option to run it.
Edit it, edit it, using our no code tools. These, everything generate here actually ends up being a no code node at if you save it.
So you can actually use it and conjunctions sorry with our no code editor.
Tools, and that allows you to link them with things like sending data or opening tensor or opening tabs and building automations and things like that. Oh, yeah, someone join us later.
Hey? How's it going? I'm recording this call.
So we're basically going through a series of Demos, you can follow along with us.
We started with creating a new chrome profile and you can ask the live chat support for a link to the recording.
Okay, so I was illustrating that you can run and edit these automations, but also click white label.
And does something interesting it allows you to generate a branded chrome extension from any automation, and this is useful for a few reasons.
It's completely standalone. So it doesn't talk to our servers.
And if you build it, using opening A or Gpd 3, you can actually enter your own.
You have to enter your own opening it, because they now we can't store opening it.
They require. Everyone who sells something go through their anyway.
So it allows you to quickly build chrome extensions, branded chrome extensions ch chat, Gpd powered products.
Basically, if an automation is useful to you, it's potentially useful to a lot of other people.
So it allows you to quickly sell this unlimited people, and we have tutorials that show you how to set up stripe subscriptions for your extensions and things like that.
It's also useful. If you have a business, because if you have security compliances and you wanna maybe distribute internal tools, this is entirely stand alone in about 30 s.
It's gonna download a standalone chrome extension that you can keep private or submit to the chrome web store.
There it is, and this is manifest version 3. Compatible.
So they'll approve it in about a week, and if it's since it's completely standalone and it doesn't talk to our servers, you can run it on premise, and that allows you to maintain all your security compliances and get set up there's a few larger enterprise
customers doing that now. So that's kind of useful.
Actually agents can now also build chrome extensions.
If you watch one of our last meetups. We have weekly meetups on Saturdays.
We built a chrome extension with one of like one of the first agents we did was building a chrome extension.
This meetup. We're gonna really an Android agent that builds Android apps and a web app agent that builds like interesting web apps from Google sheets I think that's kind of cool.
And then oh, also the sales Automation agent, which would be exciting.
So, actually speaking of agents, I should we're gonna do that next.
That's what we have time for now.
Let me check the questions real quick. Oh, yeah, the best email to contact me is rohan@cheetleader.com. I'll just drop this in the chat, anyway.
And if you wanna do like like a personalized demo or something like that, I have another calendar I can send you, and we can talk about like a like a whatever you need to automate for your business, and we have more time for that in that calendar questions.
For later. Oh, yeah, there's a general question. I'll come back to this one. Yeah.
Oh, yeah, sure. Yeah. Send me an email@rohannicetailer.com, and I'll send you my calendar for Demos.
Yeah. Yeah. No. Worries. Guys.
Okay, cool. So next we're gonna go over agents or the preview of agents because if you haven't, if you have a new account, you actually can't access agents because we have a wait.
List so like I mentioned, we're hitting our opening eye rate limit right now.
That's why most of the things you try might not be responding or doing anything.
It's because opening a is a rate limit of 200 requests per minute for Gpd, 4.
And we've allowed 500 users, and it frequently hits it.
Now so in an agents can spin up 10 workers themselves.
So that's like a peak usage. We're actually frequently hitting our rate limits.
Now so that's why we allowed the ability to add journal opening a Api key.
Someone just joined us. Hey? Hey, James, how's it going?
So we're kind of late in in the demo process.
But basically, we're going over a series of Demos and I recorded the whole call.
So you can send me an email, Rohan, a cheat layer.com and I can send you the recording, and also I can reset your task for you so you can go over these demos.
But basically, what we just did was we built a twitter responder where you can say Go to any tweet on Twitter and say, generator, reply to the Tweet on this page, and we started a call with creating a clean chrome profile which is useful to make sure that nothing else
interferes with the automations and things like that.
Okay, so agents, basically we've been working on this for a few months.
But we realize that even with Project Atlas which can build automations from end-to-end and simple language, they would still get roadblocks just like we do where you can consider a situation like Twitter.
They might update their design and use a slightly different button.
And it's hard to detect might just use images. For example, right?
And in that case, the only way we could solve that would be to build something called agents that keeps a history of the images of 20 and it's able to understand that Twitter might change their tweet button.
But they'll probably it'll probably always be slightly some color blue, and it might just say tweet somewhere.
And so, in order to solve this problem, we need something called agents, which allows us to extend project Atlas to solve problems of unlimited complexity.
And it adds dynamism and robustness, because agents have the ability to check.
If the output succeeded, so with product Atlas, it just kind of runs, and you check yourself.
If the output succeeded, and it requires this trial and error process to discover new automations.
Agents are unique because they actually check it if the output is expected is an expected result, and while they're running they have the ability and I'm gonna run a few right here.
Yeah, they have the ability to actually verify that. It's the expected result.
And if it's not the expected result, they'll regenerate the task until it works.
And so this is exciting, because when we implemented this feature, we hadn't gotten the research agent to work completely yet it was like getting stuck on a roadblock and it was stuck in like this middle actually, this one, the middle one and it kept re-enerating the task.
Basically. And I expected it to fail because it kept regenerating the task.
But surprisingly, it actually generated code that worked eventually, just by randomly regenerating the task with the same inputs and outputs.
And that's something I thought we would have to fix ourselves by writing the code, but it figured out how to fix itself.
Excuse me, that's very exciting for us, because that means it's self healing. But it's just one of these moments while we've been building this where we've had like spine, tingling results.
The first moment was when Project Atlas, when we first launched it, you could ask questions like, you can ask questions about any website or any general question.
And if it doesn't have a context, it'll actually go to that website to figure it out.
So the first time we asked things like what was the population of Chicago, it actually went to the website and figure out a result that was more accurate than Google.
And then the other time was, Do this. But well, yeah, this has happened a few times, basically.
So, that's very exciting. And then the other time was when we're doing scientific research.
That was kind of exciting, too. So it let me just go over a few examples that you everyone should have access to now, and these are basically the precursors, the previews of project of agents which you have access through in project Atlas this interface.
When you had alt S. On any website or optionus on any website.
And so the first agent that you can get access to immediately is like early before agents is the sales automation webinar, which you can send me an email for or sit contact the live chat support.
It's not. We don't have a link to it anymore, because it uses the old ui, but you can still set it up yourself.
What it basically does is it allows you to use our old systems to automate Apollo, dot I/O plus Gp, 4, to parse the emails such that you can constantly get demos on autopilot.
And we use this ourselves. That's why we built it, and we set it up, basically using a history of the users who contacted us.
And everyone who's interested in a demo. We send them a response with our link to our calendar, which I, have a round robin to our sales team, and so our sales team didn't have to do anything Apollo dot I/O.
Does all the lead generation with their database and all that stuff.
And so that was the old version. Actually. So you can set this up with the sales automation webinar feel free to email me.
And I'll send it to you and you'll just basically get Demos on autopilot.
It even does the managing of the contacts in Apollo, using their Api and stuff like that, and salesforce so that's easy to set up.
But that's the preview where the agent version of that is an autonomous sales agent which does something exciting.
So with the follow-up Ao, if you don't know what that is, is it allows you to do cold outreach and emails, and it has this huge database of emails that you can already do.
So you don't have to do the lead generation. However, the emails are all if you've used it, there all the same static emails to everyone there, I mean, you can ad test.
They're the same 2 to everyone that you're testing.
So the exciting thing is, and we've seen a few other tools do this.
Now with Gpt. 3, or Gpt. Chat, Gpd.
Is, we can do, personalize, outreach, and with that we can allow or the way the sales agent works, is it scours websites like Linkedin, Github, or any custom website you want it to.
And it starts conversations with leads who are within your persona and moves them towards a goal which might be a demo or a sale or a link, and in doing that it has to maintain conversations with potentially hundreds of people.
So the way it does that is, it maintains these people in a vector database as a Crm in parallel for potentially hundreds of conversations and that's really exciting because it does the personalized outreach.
We've been testing it ourselves. It actually does get us.
Demos, and we feel like it's gonna help us increase our conversion rate with those larger enterprise contracts which is what we're really working towards.
All the users will get access to this. So the reason we're building these 3 agents actually is because they're immediately valuable to us as startup. So I'm sure they're valuable to anyone who's building a business or a startup.
Now I mean especially just our sales automation webinar should be easy to setup as well.
So the other 2 agents, which are exciting for us.
Is the software developer agent and the scientific research agent.
I'm just gonna demo the software developer agent. First.
So you hit all tests on any website. This actually works for everyone.
You don't have you don't need a new update for this, and you can say, build a landing page as an example.
For a sales, automation sass, or whatever your business has, or whatever you want, whatever theme you want to do with a pricing section.
And a feature section.
And that's it for now, okay, you can do whatever sections you want as well just to try this out.
And it actually starts building it live and streaming it into the background.
And it does in a cool way as well, so as a consequence of solving this niche subset, which is automation, we're also solving this larger generalized problem, which, is because it can execute any code, it can generate anything which is a generalized software personal software, engineer
basically and we think that's exciting. Because this actually acts like a personal software engineer and designer.
It's even better than a software engineer and designer, because it knows the entire history of design and anthropology and the earth, and like every other company that's existed, so it you can say things like make it look like apple.com or copy like modern
designs and tail and Css. Or modern flat designs.
Things like that, and actually builds things for you like that.
Organizations have, like high converting, copy, use certain images.
And this, this is interesting. I've never seen it do this.
That's cool. These icons. So yeah, it's frequently surprising me.
But also it's iterative. It's like users frequently asking this step like, How do they edit this once?
This is generated, or how do they upload it, or whatever to an editor and stuff like that?
And what I say is, basically, if you were to hire like consultant, or pay tens of thousands of dollars to an engineer to build a website for you you wouldn't take it from them and edit it in an editor and give it back to them you would have them build it for you correctly you would
tell them what you wanted to do, you would tell them the features you want you would tell them the style and the colors and everything, and they would build it for you basically.
And that's basic. That's exactly what you have here.
And in fact, we use this to build our product this ui, if you go check out our discord, we built it in 2 days because we needed it for our launch, and we didn't have time.
And people told us we knew a better ui, so you can see we got feedback in our ui ux discord, and people wanted to.
The ability to resize the old version that we had, and they wanted to be able to move it around the screen, and they also wanted this real-time search.
We didn't write the code for this real-time search.
No one wrote the code for this real-time search project.
Atlas jetiterated the code for this, and you can go see the early rough version.
We then sent it to a designer to polish in 2 days, rather than I don't know 3 weeks that it would have taken me to build this basically.
And so this Ui was built using Project Atlas, but also the new agents.
Dashboard was built using Project Atlas. All the functionality that allows you to basically let me open it.
A new tab. This is still running. So it's gonna once this is finished, I'm gonna ask it to add some features and stuff.
But let me just quickly check out the agents. Dashboard, just to show you we're also building this using project hours, and it's helping us accelerate.
So basically the agents dashboard allows you to manage agents in a no code interface.
Such like. Monday com, basically like an autonomous AI team.
And you can have them work on goals in parallel for you.
You can edit their tasks, you can edit their context.
You can reorder their priority, and you can see their results, and they also email you results and stuff like that.
So it's very easy way to manage agents and get get used to agents without having to be like a python developer.
This also isn't a wrapper to an open source project like auto Gpt, so it works completely, differently.
We've been focusing on actually delivering value to our customers for the past year, and that library is now like completely available to agents.
So it does exciting things. So last weekend we did we did a meetup, or the last 2 weekends we did meetups where we showed agents, but chrome extensions, websites.
Next this weekend we're gonna show building.
Android apps, webex and the Sales Automation Agent.
We're gonna find a revealed that. So we've been testing that more extensively than the other ones, because it's the only agent that actually interacts without a human in the loop on your behalf on your business as Bf, so we're gonna put a bunch of
warnings that we're not liable for what it does, because it's kind of crazy.
He can do literally anything. So but we're testing it in extensively to make sure, and we put guardrails, and we teach it, because, as you can see, we've set up the system to manage agents in sort of a project management interface on the back end.
We've also set it up to train them like employees.
So we can vertically scale this and horizontally scale this infinitely this framework that we've built, basically, and we can train these agents like employees as users both run them and test them.
And even when they fail. So I mentioned that it has the ability to check when these things let me just run one of these, so you can see what it does basically.
So when you create an agent, I just did a analyze latest research on Gpt.
40, no. I sit down. Okay. Hold on.
Let me try it again. Okay, there we go.
I'm gonna deploy this agent, Wayne actually.
Let me show you the process of running them.
Oh, no, we're hitting our right limit. Okay, I will show that it's okay.
I'll wait till the next update is live.
And you guys can get access to that. But basically you can access the precursor to the software, to the scientific research agent.
And we built this interface. Maybe I'll put put this here.
Also using project Atlas. Okay? So if you want to do this, I get an access to the scientific research agent.
You can search Google scholar.
Gpt. 4. You can go to any Pdf, let me check if that's done.
Oh, yeah, that's done. I'll come back to this in a second, and if you click the puzzle piece, Icon and open cheat layer, click, add automation and then product. Alice, this allows you to access project atlas on Pdfs it's a little bit different than the Altest
interface on Pdfs. And then it allows you to ask basically any question to any Pdf.
Including scientific research papers, things like bleeding edge research, including like, if you're like, like a an engineer or healthcare worker, you can actually ask meaningful questions.
So you can say things like, What is llama in this context?
Hopefully that works.
Oh, no, I'm out of cloud Tass. Oh, that's why that's happening. Hold on!
Let me just reset my account. Sorry, guys. 1 s.
My logged into the right account. Yeah, yeah, I'm just out of cloud tasks.
Let me just reset my account. If anyone else wants me to reset their account to what I'm doing.
This. Let me know. Let's see.
Alright! That should be enough.
I was testing the limits so normally I have, like millions of tasks.
So it doesn't really matter, because you can enter your own Api key, and things like that.
But okay, cool. It's running now.
Help me get back to sharing the screen real quick.
What's this? Yeah, okay, so it's running this.
Now let me just restart it, though.
Agents.
Stop this. I just want to show you how it works. Okay.
And wait a second. And okay.
Okay, cool. So when you ask it to build an agent, you can give it like sort of any goal.
Not everything works. I mean, it's gonna take some trial and error.
But the fact that it gets through any steps at all is exciting, because if it gets through a step and it verifies a step, a task has worked.
We actually store that result, that code that works in a vector data vector database across all users, which means that users are helping us make the whole thing better by simply trying it.
Even if the whole task fails. So that's kind of exciting.
And we also add the idea of reflection here. So if you look closely when it's generating it, you can see that it has an initial task list, a draft task like, and then final task list that it actually improves on the idea of reflection which seems to help just because it works like
short-term memory basically. And then it generates these tasks.
And then you can watch them running in parallel. And then, as it's actually gonna run them and solve these problems in parallel.
And the scientific research agent does something cool and actually.
Scrapes all the top research papers on a topic and then openens them in new tabs.
And then actually summarizes them and stuff like that.
And that's gonna take about 20 min. So I'm not gonna let this go.
Well, I'll just see this step. This step is kinda cool.
Oh, I'm running a few agents being!
Oh, yeah, this stuff.
Okay, cool. So in this step, you see that it opened up all these research papers.
So I found those research papers in the last step, and then in this step, it's actually summarizing all these research papers in parallel.
And the idea is that when it opens all these research papers, it brings those summaries together and forms an independent conclusion.
And that's really exciting for us. Because if you look at the output and actually does form like interesting independent conclusions, this takes like a few minutes.
So I'm not gonna keep I don't think I'll wait for it to finish, because it does another step where it's like summarizes the conclusion.
And all that stuff, too. But basically it forms an independent conclusion.
And that's exciting. Because when we build software and we run into roadblocks and stuff like that, we go to Google or stack overflow.
And then eventually have to go to latest research papers to solve it.
Basically. And so this is, this is exciting. So you can actually ask it interesting questions on the bleeding edge research things that don't exist in the papers themselves.
And unless they respond in meaningful ways, it does hallucinate.
So make sure you verify the sources but it shows you all the sources as well.
It shows you all the all the research papers it's using to scrape this so you can see all the lists.
And this step, it's gonna get the summaries eventually.
And then the next step. It's gonna get the conclusion.
So that's the preview of the scientific research agent.
You guys have access to this? Like I mentioned. If you just go to any Pdf, you can ask it any question you can ask it to explain it to you like your 5.
You can ask it to simplify, like the bleeding edge.
Most interesting research that you've been interested, like thinking about.
But never! We're too afraid to ask questions about.
You can now go to any paper and ask that question, including, like leading edge scientific engineering research or healthcare research things like that.
Anything you're interested in. So I think that's kind of interesting. That's kind of exciting.
It's like a super powered web, Md. Or like a quaror, basically.
So that's kind of cool that alright. So let's go back to this guy.
So this oh, cool! He built this. That's neat.
It does a different way every time. So every time I kind of surprised what it does.
And if you did this at home you would have a completely different design, too.
So, okay, so it built this website for me. Now, okay, now, I wanted to do more things.
So now you can say, add an email, sign up section and make the font colors more blue and make it fancier.
Make it fancy is interesting. You can actually just say, make it fancy it does things.
So I'm just curious what it does. You can also say things like, you know, make it look like apple.com, or make it look like modern design.
Modern flat design, use, modern tailwind and stuff like that.
So it does that. And the idea is that, like I mentioned if you wanna edit this, you're not gonna put this in an editor, it's just like having a conversation with a software engineer that you hire that you paid tens of thousands of dollars.
And this is all simple language. What you're asking. Yup, but they're sending you is technical and code.
But it's exactly what you asked it to do, so he's now making it all blue and it's gonna add an email signup section.
And actually, it can, yeah, add, like functional tools and things like that.
Again, build actual functional tools, cause it. You can add Javascript to all these things.
So you can see like people who have made like games and the cheat code section, a color picker.
Another user. We help them. I mentioned that make something the EU needed product descriptions for 10,000 products.
And so the Openi playground, would have required a hundred 90,000 tokens to generate it.
And instead, what we did is, we asked it to generate an app that loop through.
It took a Csv and loop through, and did every row, one by one, and that actually works you can go see in the discord, like the phrase that we used to generate in.
So that's kind of exciting, and you can also play with this yourself.
Surprisingly, a lot of users are running out of task playing with this more, but it makes sense because it's visual.
When you're building these products, you can see the output immediately with automation.
Sometimes it, just doesn't work and not everything is guaranteed to work.
So you have to do a trial and error process and stuff like that.
But with these things almost every time there's a visual output you could tell it what it did wrong and how to fix it, and iterate it and make it like your own product and tool or game, or app or whatever you want and so the agent version of this takes it, a step further, if you go look at
the recordings of our meetups, you can see that it breaks it down into manageable pieces, and actually builds entire apps.
Games let me see what I can do here. Generate a web app, so a web app for a word, search, puzzle so you can build entire front ends, backends, apps, android apps.
Ios apps. We're gonna reveal an android app maker this weekend cryptocurrencies, marketplaces.
Basically anything. And the only limitation right now is a context window in Ak tokens for Gpt. 4.
So not everything. It can't do everything, but it can sort of design every sort of product you can think of now, and what I mean by that is the complexity of the those products are still limited by the ak context window.
So now I give it is that it's like an organization of regular engineers right now, who can sort of build the tools for you?
But they're kind of simple tools and things like that.
However, when open AI gives us access to the 32 K.
Model window or the 1 min model window tokens. And we're also doing research into how to build our own version there'll be an entirely new category of solutions that will be possible.
It'll be kind of like going from 8 K. Internet to one Mega, like a tech 1 GB Internet, basically so that's going to be kind of exciting for us. So you can now test this out.
See what it does. It's cool. It actually does build functional tools.
But we think that the complexity of these tools will get much, grow exponentially, as the token window increases.
Okay, so right now, it's building me a web app for a word.
Search, puzzle gain, and stuff like that. So that's kind of cool. Alright guys.
So we're near the end of the call. I'm gonna open it up to general questions.
And I'm gonna go back and answer all the questions as well.
So let me just go back and check all the questions while this runs, and and I'll make sure to stay and answer everything.
And then, if there's any other questions that you have or you didn't feel comfortable sharing here, feel free.
Email, me privately at Rohanna cheetlayer.com directly, and I can also send you another calendar where we do one-on-one demos.
Sometimes users have unique use cases. They want to show me or try out and test out.
And we can workshop the prop together to see if it works and stuff like that.
So, so, okay, so I'm looking. Let me look at Darren's question.
I'm gonna create a fairly simple search and collect used to happen 15,000 a day a month each time the search is done slightly, added so that the search is automatic based on the parameter. Oh, yeah.
One way to do this. Actually, we're going to show cool example.
This weekend where you can use Google sheets as input.
And we're gonna make like a web app builder.
There's some tools where you can build like websites out of Google sheets and so we're going to show you how you can use Google sheets as inputs to these things.
So that's I think that's gonna be super useful.
So you can have whatever parameters you want to.
Automations and edit them in a Google sheet or have them like linked to other automations from cheat, layer, zapier, and stuff like that.
And that's a big use case. We've been working on users and asking it for a while, so that would be good. I think.
Yeah, that should help you do that. Set that up daring, and 50,000 a day since you're running it.
Well, it depends on where, like, where you're running.
If it's like a public source, they own generally it's not.
It's completely legal. They don't generally care what they'll still rate limits.
You, and so what we recommend doing is setting up proxies and doing it on cheque cloud.
But we have bright data proxies that we can set up for you also.
Users have wanted to use their own proxies as well, so we can help you set that up.
And so that's entirely possible. Some users do scale up like we have a recruitment firm, for example, that is, does scale up like huge lead generation operation.
And that's definitely possible. I just wouldn't do it entirely on your IP so you get blocked and things like that.
But it's possible as well to run 15,000 automations in a day, because it doesn't consume fast when you run it locally.
So that's also useful. We have some users who have set up like huge arrays of raspberry pi's, or virtual machines and things like that.
So that's the wild end of the spectrum.
Also some users, because you can sort of use sheet cloud as an Api, basically, we give you a web hook to trigger T. Cloud.
So some users have set up Sas bubble services and things like that that go do the automation using our Api and then provide that as a service to people and charge them.
That's kind of cool. Okay? So I want to automate pulling prompts. I'm at.
Checking out Sky's question that created an excel spreadsheet and paste, then runs in Gd.
4, and waits for oh, actually, this is cool. I think we're about to publish something like this.
Someone asked this in a support, and well, this one of the support staff working on this? I think so.
There's a way. So actually, a bunch of users have automated the Chat Gpt interface so that you can just like, take a Google Sheet.
We've. I think we have that somewhere, and we can just publish that.
But the other cool thing that users doing now is like, Hey, dynamic outputs for the chat.
Gp interface like going sending it places like tweets and stuff like that.
So scrape the completion, and pasted in New column, and the same exact excel spreadsheet.
Yeah, that should definitely be possible. Yeah, except for now, Google sheets, we haven't trained. Excel.
Api. Yet we do have the ability. If you do. The Google Maps Automation.
So if you say, scrape Google maps for plumbers, and you Jersey, it'll output to us a Excel file.
And so we have that ability. We just haven't trained it entirely in product Atlas to use it yet.
And the reason we have it is because there was a private equity firm who just wanted, who are super strict about their security compliances.
So they most people who are strict about that. They don't really ever use Google sheets, anyway.
So yeah, that is an option. And you can set that up as well using the know code editor.
And from there repeat the action. 25 times every 3 h.
Yeah, that's responsible. Oh, the 25 times.
It's probably because the chat Gpt Api has a limit of 25 requests every 3 h right?
So that should definitely be possible. Yeah, we can even schedule that using the scheduler.
So. In fact, it might even be possible to do this, using like a string of phrases using Project Atlas entirely yeah, I think that's what the support is working on.
We have support. Staff. Who got this question recently? So maybe you asked this question.
Actually, so, yeah, I think we reset task.
I'm just gonna go down there. General questions real quick, just to respect people's time since we're at the end.
But of course, if if we run out of we don't have time, feel free to email me@rohanadette.com, the update is gonna be available hopefully tonight, maybe by tomorrow, can I create an application with this tool that I can sell to customers. Oh, yeah, definitely.
So we went over the white label. Example, however, agents can now also build entire products and let, like you saw it downloaded.
The code. So it's completely standalone. You have complete access to the code.
You can build like as chrome extensions, websites, things like that.
You guys even have access to the project Atlas version of building these websites.
Oh, yeah, let's look at the output. It made it blue.
There's an email sign up somewhere, hopefully, anyways. Oh, yeah, yeah, I know.
So yeah, it'll build things. And if it gets it wrong, actually, just tell it what it got wrong.
And Gpd 4 is much better at this alignment problem.
So it's able to iterate and build. That's how we built these interfaces. Actually.
So I'm using it because I'm confident enough that it's working very fast for me.
It's saving us time so it's for me.
It feels like honestly, like a assistant. That's a super power junior developer that knows like, I mean, probably even like a senior developer at this point, that just knows everything.
But they still don't get everything right. The first time we just have to iterate it.
Basically, oh, yeah, definitely, we get happy to set up a call.
Ask it to model features that domain and build it oh, yeah, so that's a cool thing. When you say stuff like this page, I'm answering Kim's question. So when you go to a website and say, like this, page, it'll generate an automation, based on that context, so you can say, like make this
page look like apple.com, or make this look like that, or you can even paste in the HTML of what what you or the style of what you want to copy and say, make a website that uses this stuff, and that'll it'll be able to copy that feature and
make it look like that. The other cool thing that you can do is like I mentioned in the Twitter Example, where we replied to this Tweet.
Since this was done in language, but we generated this like using Gpt.
4. So and uses dynamic input as content. So you can do things like build machine learning tools, using simple language like sentiment, analysis or classification.
So you can say things like if there's Tweet, is positive reply.
If it's negative, send me an email or yeah, things like that.
So I've seen users do interesting things like sentiment, analysis.
Analysis on tweets for automating trades and things, and that was interesting.
I think, okay, so yeah, that'd be quickly go down questions.
Yes, you can make it generate quote, specific like, you can make it generate wordpress plugins, for example, and it'll generate the Php code for wordplus wordpress plugins, because it knows what that is.
However, it's not gonna work. The first time. All always, because generally it requires some kind of trial and error process.
It used to like it generally when we're trying new things that we haven't discovered yet.
It like gets to maybe step 3 or 2, and you need to figure out what went wrong and tell it.
Oh, this went wrong! And then that's how you finish it.
Until we get to generally I am, I suspect it will be kind of like that.
But how we've built this framework to train these agents in parallel, like like employees, basically.
Hmm, can I be specific to hens? I want a software developer project.
Oh, yeah, yeah, you can actually give them personas like you can tell them.
That's what we do internally to make these agents, as we tell them to be like a professional software engineer.
But you can also say things like you are a professional marketer, and that actually does seem to work.
We have a few tutorials in our Youtube on like tricks on prompt engineering.
So, doing things step by step, reflection asking it to look at its results.
And also like telling it to act like a professional software engineer or marketer before you start, actually does meaningfully change the output and make it better.
And I think it's just because it's like we discussed this in one of our meetups is it doesn't have the predictive ability.
So every word is generated on every previous word, only using a probability matrix.
So the reason things like these work is because if you start with your professional software engineer that completely changes the probability matrix and highly skewed skews, it to only things professional software engineers would say or try so I think that's very powerful.
It's just like these kind of tricks are basically opaque ways to manage a huge probability matrix using words.
But it works, and people are discovering things.
If you look at the latest research papers like these, discoveries are all in simple language and words, and they discovered, like the latest bleeding edge.
Research papers are just like the trick is, say things do say, do it step by step, and that works.
If you say do it step by step that works, and there's a bleeding edge research paper on that.
So we can basically discover these things in simple language. And you can see our discord of how we are basically discovering these things at the same time as a bleeding edge research, which is kind of exciting.
Oh, yeah, I'll reset your task. Let me just copy that email I don't know if it sees it if I copy it, but I'll just copy it into the clipboard and reset your task also if you ran out of task feel free to send me an email just so we can
get our actually the copy to the recording, and I'll reset your task so you can go run through it again when you have time to run through it again.
Oh, yeah, for Google maps, you can say things like, scrape Google maps for plumbing or plumbers in New Jersey.
And it actually project. Atlas builds the whole automation for you.
I would try it out, and it uses an enrichment.
Api to get data that you can't get from Google Maps things like revenue.
The number of employees, like the history of revenue and the contact information that typically you can't get from Google Maps.
So that's kind of useful Google search. I think we're gonna release that.
It's related to another agent that we wanna release.
And we just haven't released a predefined agent.
But you can find all the predefined and supported automations if you check the cheap codes page on the dashboard, the key codes, and this is the full list of currently everything that's supported these all have one click buttons to instantly run them.
Like, like the dark mode one that I did, and video tutorials to show how they work and.
How, and where? Oh, the agents dashboard! The final results it actually emails you. The results.
But also you can see the conclusion here. When we did the research papers.
In conclusion, Gpd. 4, is an impressive language model that has high levels of understanding and generating medical domain.
It is also talked about it that see it talks about the Bar Exam research paper, but that was one of the research papers.
It, pulled out our due to safety and limited accessibility.
Is still restricted to paying subscriers. Okay, so that's the latest papers that it talked about.
We also did one, for, like the final cure for Alzheimer's, and we talked about this in our last meetup, and actually provided like interesting avenues to like continue the research based on the latest research that was valid.
What the stuff that used was actually valid. So that was interesting.
I also I've also used it for like interesting questions, and cosmology, and actually does provide like interesting scientific like possibilities to prove it, using observation and stuff like that.
So that that's cool. If you guys have deep industry insight in something I'd recommend trying it out trying, especially like the scientific research agent, or just opening up Pdfs and stuff like that that's useful.
You have access to that as a free account. I mentioned. There's a wait list to get access to the subscription to the agents.
Currently, we're only allowing 500 subscribers.
And actually, we just hit our rate limits. So we're probably gonna have to implement the waitlist soon again, anyway, until we solve this problem.
But users. If you have your own. Open AI key you can add it here to run unlimited agents and unlimited project.
Atlas requests doesn't consume any tasks, so that helps us out as well, and.
Okay? Yeah. Oh, yeah. Feel free to send me an email, rohan@cheetahir.com, and we'll set up a I can send you my private demo calendar.
Oh, yeah. Feel free to. Oh, yeah. Sorry you have to go, Nathan.
Feel free to send me an email. Rohan and cheatlayer.com.
And make a tool. Oh, yeah, he could do a coloring book.
Creator, I'm not asking answering Brian's question, though can I make a tool like a coloring book?
Creator, that creates X. Coloring pages based on prompt or an Api request.
Can it make images? Yeah, I can do Dolly images, too.
So that's interesting. Oh, maybe you could generate black and white coloring book images, using Dolly.
That should be possible. If if you discover cool things like that, please share them in the discord, and the cheap codes.
Page clicks submit, cheat sheet code. We're looking for users who are like really good at finding these to share them.
And we're also incentivizing users. So you'll get a check-out G cloud tasks for life.
They'll gonna access to the private discord. And we're also setting up a way to pay users who discover these things per run.
So if you're like one of the users who discover the one of the more popular automations, you could earn money constantly recurring revenue constantly for life as we grow sustainably okay.
That was the meetup on Saturday is at 12 Pm.
Eastern every Saturday, and it you'll see it live on our Youtube.
So if you subscript or Youtube, you'll also get access to it.
But we posted to our socials on the Facebook group, and the discord cool.
Alright guys, I think I just got through all the general questions.
So I'm gonna let you guys go. I know we went way over, but I'm always happy to answer any more questions.
Feel free to send me an email Rohanna cheetlayer.com.
And I'm gonna let you guys all go. Now have a good night, guys.
See this weekend.

MEET 4: 

 All right, we're live. Thank you guys for joining us. Sorry for the delay and getting started. We've got a really special session today. Lots of awesome guests and an awesome moderator. So with that, I'm going to hand it over to Kumar to kick things off. Well, Harrison, thank you so much for having me. Thank you everyone for joining this discussion.
 Dari for starting a little late, I think that was technology problems in my end, but I'm super excited about this conversation. I'm thrilled by how many people are joining it. For those, I think that core goal is discussing the intersection between the huge amount of interest that's happening around AI and machine learning, large language models, and tools specifically like chain and the topic of education, you know, I work in the Obama White House as president.
 Nguamma's ed tech lead for almost eight years was there for lots of important developments in education. But I have to say that I think the role that machine learning can play in education is potential to be the biggest thing that'll happen in our career. And so I'm excited about its potential, but I think there's a lot of open questions. And I think this developer community is going to be a big part of how do we start to figure out these answers. So as Harrison said, I'm at Schmidt Futures. It's Eric Schmidt's Science and Tech Foundation.
 I'm one of the vice presidents. I'm also the executive sponsor on a program called Learning Engineering, which physically focuses on how advancements of machine learning can improve our understanding of human learning and improve educational outcomes. We have been incredibly, the work that we've done in this program has actually lasted over a couple of years. So we've been enthusiasts about the potential of these technologies for some time. But I would say the past six months have been quite revelatory in just a huge amount of public interest.
 and also the speed of development. And I think one of the key questions is going to be, what are going to be the user communities and tools that will develop in this area? And I have to say that we were definitely fan-girling and fan-boying when Harrison agreed to do this because we've been talking internally about how tools like Langchain have the potential to create these new scripting languages that can really help create much more powerful tools and have
 of these LLM models that are popping up. So why don't we first start with just like a little bit of context. Some people I think will be very well right up on this and some won't. We have a bunch of people who are from the education community and the tech community who are joining. So Harrison, you know, like not to belabor, but it would be great if you gave like a little bit of what is chain and why are people excited about it in the context of large language models? Yeah, absolutely. And thanks for. Thanks for the time being. Thanks for today.
 for joining as mentioned before. Lengchain is a framework for developing LLM applications. So we're developer toolkit. We've got a package in Python and a package in TypeScript. And a lot of the things we provide in terms of making it easy to develop LLM applications involve connecting it to other sources of data and computation and a lot of tricks to tips and tricks to really eke out kind of like.
 the best performance of language models, whether that be chaining or different types of reflection or things like that. So, you know, language models are this incredibly powerful new technology, but they still have a bunch of shortcomings in terms of not knowing about your own data and not being connected to other sources of up to date, data, up to date, computation, and not being really like personalized as well. And so, you know, as we start to talk about education and I'm sure we'll hear.
 from a bunch of presenters, there's a lot of difficulties in just using language models. Some of them can be lack of factual understanding. Their responses can sometimes be hallucinated or made up. Another big part is personalizing it to a course, to a user's learning level, to anything like that. Langchain provides a bunch of developed virtualing to make that type of personalization as easy as possible. Yeah, super.
 powerful and one of the things that I find so interesting about it is that it's not just a concept like people are actually using LinkedIn in lots of powerful ways. So not only did you build build it and put it out there, but immediately started to get a ton of use and people started to build it out. So I think one of the things that I'll sort of recommend, we have all these great folks who are participating is folks as we start to go through these different use cases, you know definitely.
 drop in your questions along the way, but also what are ways you're using Leng Chain, and if you're doing anything specifically on LLM's and education, feel free to drop that a little bit in the chat and we'll follow along both on experiences you're having, and then questions you might have that will have in an active Q&A, and I also wanna call it, Anjuli on our team, who helped us set up this conversation. So why don't we do a quick, we're gonna have three quick presentations just on how people are starting to use this stuff just to help ground us.
 And then we'll go into a Q&A, both on what those presentations are about, any questions you dropped in the chat, as well as ideas, Harrison and others have. So why don't we go through those? First up, let's have Joshua Ling, who is a CEO and co-founder of Podsy. Joshua, tell us what you've been working on and how the community can benefit from those early experiments. Sure. Can I actually share on my screen?
 Even that I struggled to just sign on, I might not be the best answer, so if you can figure it out, then sure. All right, perfect. Can everyone see my screen? I see mine or I see mine on the podcast. I'm going to see. I can see it. Josh, you're good. Cool. Yeah, my name is Josh, like you mentioned, and I am the founder of Podsy. I'm a former
 I'm a former middle school math teacher, turned software developer. And two and a half years ago, I found it, Podsy, which is a nonprofit ed tech dedicated to improving student learning outcomes and empowering teachers by making it easier for them to utilize research-backed strategies in the classroom. So to do this, we've built a free web app that allows teachers to provide personalized review for students throughout the school year. As a quick overview, how this works is we give each student a personal deck. And as they complete assignments,
 on Podsy, every question from the assignment then gets inserted into the personal deck. Then we have a spacing algorithm that powers this deck and decides when the optimal interval between questions is to when students should review a question again in order to maximize their likelihood of retaining what they've learned. Specifically, our apps actually inspired by a 2014 paper from Robert Lindsay and his colleagues. In that paper,
 They showed that personalized space out review over the course of a semester at least can actually improve learning outcomes by 16.5% in classrooms. So currently we, we've actually started experimenting with leveraging large language models in our web app about half a year ago, we first started by allowing teachers to generate questions based on background text that they provide and we're just hitting open a eyes turbo 3.5. .
 of chat model. So as an example, here we are pacing in text about planet animal cells. It generates five questions that teachers can select from. And then once they've selected the questions they want, we hit the endpoint each time to generate answers again. And then once they've actually decided which questions they want for their assignment, they can either add it or discard it. Some other features that we've been working on include.
 a chatbot as well. It's an alpha feature that's not actually available to teachers and students yet, but the goal here is to build something similar to what Khan Academy is doing with Khan Vigo and allow students after they answer a question to ask questions to a tutoring chatbot, to address misconceptions, ask clarifying questions, and overall just get a deeper understanding of the underlying concepts that the question was assessing them on. So as you can see here,
 What we've started with are some lower hanging, perhaps more obvious implementations of large language models that the turbo 3.5 chat model from open AI might just generally be good at. However, as we start developing other LLM based features, we're running into use cases where we need these base models to be more powerful and more accurate. And that's where Langchain has come in. So we've been exploring Langchain recently as a way to give.
 give the chat turbo 3.5 model access to specific tools. And I think to explain how we're thinking about using Langchain, I want to walk through a specific example. So specifically, right now during the summer, one of our main priorities is to make pods you work well in math classrooms. And right now, it's currently not optimal for math classrooms, because as you might imagine, if a student sees this specific question.
 and over and over and over again in a personal deck, they might just memorize the answer negative 36, rather than actually being, rather than actually practicing whether they know how to solve a multi-step equation. So the way that we're thinking about using large language models to address this problem is to generate variations of this question automatically when a teacher creates this question. So for example, we might automatically generate a question like five.
 times x plus seven equals 2x minus 40 or something similar. And therefore, prevent students from memorizing the answer. However, unfortunately when generating these variations, we're realizing that a lot of times they're just not great at solving math problems. So for example, it might just generate an inaccurate answer for a problem here. We've tried things like, you know, chain of thought prompting in order to make it more accurate. So for this specific,
 by adding this thing through this step by step. It actually did improve it. However, it didn't seem to work that well when we started using larger numbers as well. So actually, what we're currently at is we've been looking into using like the program as a data language models in order to solve this problem. So just a quick overview for those of you who might not be familiar with programmated language models. This allows the language model to run.
 present a math problem as a computer program, and then it actually gives it access to a code interpreter to execute it and then calculate results. So at the moment, we're actually iterating a lot within the Lang flow library, and we're just trying the different tools. We tried the basic calculator tool, this program-aided language model tool as well. And then I think we're also hoping to try out the Wilhelm Alpha tool to see if we can get consistently accurate results in generating answers to this.
 for these questions. So yeah, if anyone has any suggestions or thoughts on how to best implement this, I think this is something that we're really interested in learning more about. And looking ahead, well, if you want, if you have thoughts on how we can improve this, this is my email, I'm sorry, that should actually be podsie, not that extra D there, should not be there. But yeah, looking ahead, I think we're excited to try using Lengchain for like much more sophisticated and powerful هنا eve.
 things like giving access to like SQL queries against our database in order to serve as a much more robust and powerful teaching assistant so that teachers know where to target and help students specifically in different areas. Cool. Super interesting and I love all the questions everyone is dropping as well as the different ways that they're learning I mean potty is a great example. You know we met you know Josh on his team.
 a couple years ago and they've been really building out this idea of taking a core idea that exists in the learning science space, which is a role of space for repetition and then adding a lot of engineering on top for how to actually bring this to use for teachers. Now, obviously, there's important questions in education, like obviously these LMS are particularly good at math right now, but they might be quite powerful in building feedback groups to students which end up being very important in learning. So why don't we do next step, Wesley? Wesley, do you want to talk about that?
 Call over to value work. Sure, thanks. Oh, let me share my screen. Right. Hello, everybody. My name is Wesley Morris. I'm a second year PhD student at Vanderbilt. And I'm really excited to tell you about some of the work that I've been doing with a project called Intelligent Textbooks for Enhanced Life.
 long learning or ITEL. I'm part of a lab called Lear Lab at Vanderbilt and we're a part of an institute called AILO which is a NSF funded institute for adult learning. And the project that we're working on right now is called ITEL, intelligent textbooks for enhanced life long learning. So first I'm going to give you all a little bit of an overview of our project and then after that I'm just going to walk you through some Jupyter notebooks.
 to show you some of the workflow that I've used recently using Langchain. I've worked with machine learning models with large language models for about two years, but I am brand new with Langchain. I've only been working with Langchain for about two or three weeks. And so I'll walk you through a little bit of my learning journey here with Langchain. So what is itel? You got everybody's familiar with traditional textbooks.
 and digital textbooks. But an intelligent textbook is something that can interact with the student. It can recommend activities for the student and provide feedback to the individual user. So, ITEL is not a specific textbook. The whole point of ITEL is that it is domain agnostic. It's a framework for generating textbooks. In short,
 developer can provide any kind of informative text in a correctly formatted MDX file. And I tell will automatically generate an intelligent textbook based on that content. So for now, we're using a textbook from OpenSex for our prototype. And the main use
 feature that we have in the textbook right now is a summary writing at the end of each section. So the user will read the section and then at the end of the section they'll write a summary. And I trained two longformer models to evaluate the summary on content. In other words, how well does the summary reflect the content of the source and wording. In other words, how well does the summary paraphrase the source and
 and the type of wording that it uses. So we provide feedback to the students currently and the current textbook. It goes through a junk filter. If it finds out that it's been plagiarized, it'll get stopped. If it's a low quality summary, we'll fail it on wording or content. And then if it's a good summary, then it will pass the summary. Um, one special thing.
 The thing about ITEL is that it's designed specifically with the needs of researchers in mind. We're researchers. We're not directly in the education technology business. And so as we're designing it, we're thinking constantly about how we can use it for research. So we're collecting data on the user behavior as they use the textbook. We're collecting key stroke logging data as the student types the summary.
 And then we're also collecting attention to text data. So how long does the user spend looking at each subsection of the textbook? And so that's where we are so far, but we are planning on adding new features to the textbook. And I'll show you what I've been doing here. Okay. So one of them is question generation. And I started doing this before.
 Before I found out about Lanchine and I just want to show you what a mess this was before I'm not going to put you through the torture of walking you through this. But all I want you to all I'm trying to show you is what a nightmare of regular expressions it was to do output parsing on the on the output from open a eyes chat you can.
 So moving up, um, Leng chain offers something called a prompt template, uh, which makes it a lot easier to feed the prompts in to the large language model. And so that made it a little bit easier. And then finally, um, they offer a feature called response schemas. So in this case, we're generating recall summary.
 and inference questions for each of the subsections of the textbook. And using the response schema, we can generate a question, a correct answer, and an incorrect answer for each of the subsections. And later we can use the output to train another model to be able to to
 tell correct answers from incorrect answers. So we have two problems. One is generating the questions and the other is evaluating the answers. And so using the response schema, we can do a prompt template and then iterate through each of the. Different subsections to generate a nice little JSONs that we can easily convert into a data frame. And so this.
 This has kind of saved us a lot of time and effort. And we can create a data frame like this that creates the question, a correct answer to the question, and incorrect answer to the question, and so on. And it can all be done automatically, which is our whole goal with I-TEL, is that it can be domain agnostic and be entirely automatic based on the content provided by the developer.
 So output parsing is one of the uses that I've found for Langchain. The other that has been really convenient is using the vector stores for embeddings. And this is a much shorter and cleaner notebook. So I'll walk you through this just to show you how easy it is to generate a vector store and use it for. Looking at.
 at similarity between the summary and each subsection of the textbook. So the point of this is that we'll be able to take the summary. If the summary fails, the content test, we can tell the user which subsections they might have glossed over or missed and redirect the user back to those subsections. And then also in terms of research, we can look at the relationship between time on text for each of the subsections.
 and which subsection the summary is most similar to. So all you have to do is load the embedding model. I used, what did I use? I used the mini-LM because it's faster and more convenient. And then just generate embeddings for each of the subsections in the textbook. And the inference is just this.
 All you have to do is put it in and it'll give you the most similar subsection and the similarity score. So those are two of the use cases that I've found with Langchain in the past couple of weeks. And but I think where Langchain is really going to come in handy is when we start integrating intelligent tutors.
 and we can start fine-tuning chat bots basically on the content of the textbook. The agents that are provided by Langchain are also look really exciting. And I'm super psyched to continue working with Langchain to develop ITEL and to make our textbook better and better. Here's our lab, and that's all for me.
 Amazing, thank you so much. I think it's like exciting both for like, you know, the quick uptake that you're seeing, but then also some of the use cases, some organization, you know, bots are attached to certain bits of material. I think that the ton there. So why don't we go next to perpetual? perpetual you want to talk about your work? Sure, thanks so much, Kumar. And thank you all for having me. Very excited to talk about a little bit more about the work we do at the Learning Agency Lab and how it intersects.
 sex of large language models. So I'm going to try sharing my screen as well to help facilitate this conversation. I hope you all can see my screen. OK, cool. And so as we're thinking about how do we leverage large language models and also length chain as well in solving educational problems, I will say that the work that we do at the Learning Agency Lab is probably slightly different from what we've seen so far.
 with Posse and with ITEL, we aren't necessarily developing a specific product or tool, but we believe in creating data sets, creating data science competitions, and creating an environment to attract innovators, and data science and machine learning to leverage the power of large language models to solve critical problems in education and address important research questions. But a high level where we connect with large language models is through these open data sets that we build and release. And through this,
 these data science competitions that we run based on these data sets to define critical educational challenges that we believe the latest innovations in NLP and large language models can address. So the real meat and potatoes of our work at the Learning Agency Lab is through these open data sets and data science competitions. So at a high level, what we do is we try to partner with education-focused organizations. It can be a nonprofit, maybe even a public agency who has specific resources.
 research questions or specific data that they believe AI, machine learning, NLP can use to build important tools or algorithms that can help students can accelerate and improve learning and help teachers and educators as well. As we're partnering with these different organizations where identifying key research questions, we're defining important problem statements. We then try to translate those problem statements into specific machine learning tasks, whether it's
 automatic grading, labeling, classification, or content recommendation through recommendation engines. We try to see if there's this problem in student learning or in the educational system that we want to solve. What specific machine learning tasks and applications can directly link to that. Once we've identified the machine learning task and we built the data set to use, we then run a competition where we're crowdsourcing solutions to this problem. So specifically, we win that.
 within the context of NLP and large language models, that's where we see this connection really emerge is that we're crowdsourcing large language model-based solutions to address specific educational problems. To give a specific example of this, I can talk about our flagship project, which was the feedback prize. So in the feedback prize, we identified a critical problem, you didn't struggle to write, and they don't receive a lot of feedback on their writing. And this is particularly a problem in the context.
 The middle school grades and the high school grades, there's some data showing that very few students graduate from high school as proficient writers. So we identified this problem and we also identified a machine learning solution that we now see this emergence of automated writing evaluation systems which are powered by large language models that can look at student writing and that can evaluate the piece of writing for its quality and potentially provide feedback. So with that, we ran three different competitions.
 in our series to look at this issue of student writing and assisted feedback. I can go into more details about how these competitions were able to leverage large language model-based solutions, but at a high level, our three competitions looked at one, building a large language model solution that could identify different components of an argument in a student essay, two, building a large language model-based solution that could evaluate the quality of these different argumented.
 components and then three, building a large language model that could have a specific focus on language proficiency when it comes to writing by English language learners. These three competitions we were able to crowdsource over 100,000 solutions were really excited to report that the winning solutions had accuracy at the level of humans and the winning solutions were indeed large language model-based solutions. Many of them were actually ensembles of transformer models which is a pop
 type of large language model. So just to make this a little bit more practical and concrete of what the feedback prize large language models can do, they first can take an essay and break it down into smaller chunks through segmentation. So they take an essay and parse it out into different smaller units that each perform a specific argumentative function in the essay. Then they label those components based on seven different categories like a lead, a position
 or the main thesis statement claims and pieces of evidence, and then they can also evaluate the quality of these different argument of elements. They can say, okay, this piece was more effective or this piece was adequate, or actually this section right here, this piece of evidence was ineffective in supporting the overall argument. So that's just one example of how we're creating data sets and data science challenges to create large language model-based solutions that can perform educational tasks to ensure
 improve learning. But before we get to that stage of having the large language model based solution, we believe that a large language model can only be as good as the data that it's trained on. So a core component of our work is building specialized, high quality data sets to train these large language models. And because we're publishing them, we believe that the openness of the data set and also the openness of the algorithms, making them open source ensures that we have transparent.
 see reproducibility as well as algorithms that can be further analyzed and researched for other issues. So we build these data sets. It's a pretty thorough and comprehensive process, but we try to make sure the data captures different learning and assessment activities. We also prioritize diversity and inclusivity in our data because we really value fairness in our algorithms. So with that being said, when we're looking at these large language models.
 But we don't merely just take the large language model with the best score and a competition and then sort of call it a day. We continue to do evaluation because we want these solutions that are being produced in competitions to actually work and be effective in a real classroom setting and in a real learning environment. So our key metrics when we're looking at these large language models are accuracy, efficiency, and fairness. In many of our competitions, we have one going on Kaggle right now.
 Google is our big platform for running data science competitions. We have this prize and incentivize efficiency track. In essence, what we do is when we have an NLP based competition in particular, we want large language models that are simple, that are fast, but that also have high accuracy. In addition to efficiency, fairness is increasingly important concern in AI, but is especially important in education as well. So we take a lot of steps to make sure that we're not producing large language models.
 models or encouraging the development of large language models that would be biased and disadvantaged historically marginalized students. In order to do that, we take steps to minimize biases in the data sets through the data collection, as I mentioned earlier, we also take steps in designing competitions that can address algorithmic bias as well. So ultimately, through these data sets and through these data competitions, we're able to then yield large language model-based solutions that we hope product developers.
 or even nonprofit organizations or school agencies can use in their actual tools and platforms. So what we hope to do next as we continue in this work, we try to seek out partners who can use these solutions in their platforms, in their environments. We try to ensure that there's alignment between what the algorithm can do and what specific features or services that a tool developer is trying to provide in their platform.
 and their environment. And we also can consult and thinking through what are specific user-centric approaches, what are specific features or functionality that these large language model-based solutions can perform once they're integrated into a product. So that's sort of an overview of how our work kind of intersects with large language models. I think in the last section in talking about product implementation, I think that's where the power and promise of lynching will really step in.
 thinking about how do we take these sort of, you know, production-ready models, but then use it in a tool and in a product application that directly serves the needs of students and teachers. So overall, we believe that open data sets and data science competitions can really promote collaboration and innovation in the field of AI and NLP. So if you're interested in learning more about our work, if you're interested in potential partnership or consulting opportunities, because we have many different competitions that we're hopefully launching.
 in your future. We even have one running right now. Feel free to reach out to us. I have my email address up on the screen and we'll definitely love to connect and talk more about this work. Amazing. Thank you so much. That was awesome. Yeah. And as you all know, I wholly subscribe to this view that you have to actually invest in the data sets if you're going to get some of the upside when it comes to some of these applied use cases. So Harrison,
 Why don't we bring you back? And just to start off, it'd be great. Just your sort of reaction. You're seeing the space that all really fast. On what you think the potential is in education, both for LMS overall but lynching. And then some of you sort of off the cuff reaction to some of the presentations and ideas of use case and sort of thoughts of the community. Yeah, absolutely. I actually have two questions that I'd like to get, like all panelists thoughts on as well. And then this gets to.
 like my reaction until a lot of them as well. I mean, one is around, like I think, or actually, yeah, so I think the thing that starts to become really powerful is connecting language models to other sources of data, whether that be things that people upload or other datasets that are curated or anything like that. I think that's one of the, and I think that's one of the areas where Linkin helps out a lot and helps Augment just to link.
 which models themselves. And so that's, I think that was present in kind of like everyone's presentation. There's another kind of like aspect to that, which I would love to get the panelists takes on, which is basically personalization of education to specific students. So now different than like, you know, like someone could upload a textbook, but the way that one student might learn it might be different from the way that another student might learn it. And I think like this is part of the power, the gendered FAAI in education, is you now can start to have kind of like,
 like tailored plans or tailored tutors for particular individual students. And then said, I'd actually be really curious to hear everyone's kind of like take on that and how they're thinking about that, both in terms of like, from a product point of view, like what's the priority of this, relative to other things, but then also from a technical point of view, like how exactly do they imagine kind of like implementing this? Yeah, Joshua, what do we start with you? What are your thoughts on like, let's say there was a file that just kept the user history?
 of how they've interacted with pods in the past. And one of the lunchcrain scripts was like, well, review the history before you serve up the next piece of thing. Yeah. So I think we've already started trying some personalization especially with the tutoring chatbot. Like allowing, like the prompt for that tutoring chatbot is given this student's answer as well as like the previous conversations you've had with the student about this specific question.
 like guide it and they guide the student in a secratic manner so that they can like clarify this conceptions get a deeper understanding of the problem. I think when it comes to personalization, we almost do that as a spectrum. Like on one end, you might think of it as just you let the student interact with these large language models. And then that's it, like you let them kind of go off on the Wild West and their own. I think what we're really interested in doing.
 is involving the teacher when it comes to the personalization aspect. So we find a lot of power in, so you mentioned like giving it access to, giving large language models access to external data sources. We envision using large language models almost as like a proxy layer between teachers and students. Like we wanted direct teachers to what students need to have addressed most urgently at that moment. And then letting the teacher actually step in
 to decide maybe it is like letting the student interact more with a tutoring chatbot, or maybe the teachers should just directly interact with that student. I think that idea is much more compelling in the short term, especially as we're still dealing with like accuracy and hallucination issues. So I think like part of the reason why we haven't released the chatbot yet is because we're still looking to build in the future where like teachers can continually monitor these conversations and then step in whenever necessary to be able to like, if necessary, like steer the conversation back on track. Interesting.
 You imagine doing that helping flagging, to the teacher automatically, now you should think about stepping in and if so, how do you think about that? Is that just a random call that's running in the background that's yes, no, for whether to flag to the teacher or something like that? Yeah, I think so. I think it's like, if you can potentially flag, if you notice that the conversation is going off of what the happy path might be,
 like for this week one example. And I think in general, too, like instead of just like individual conversations, like I mentioned, we'd like to explore how we would use chain to give the ability for these models to make SQL queries against our database. I think that's like one area. We're talking to teachers in the thing, one area that they consistently give feedback on is, just knowing, like there's
 so much data to actually work through when it comes to student responses. So how can we actually point them in the right direction? Given it. What are some of the types of questions that they're asking in terms of like or hoping to get out of like the students responses? Like what questions, what types of questions are they asking? Like is that the main one? Like addressing potential misconceptions I think is a big one. Because a lot of times like what might be holding a student back from mastering some cases.
 that is just one gap, one like crucial gap. So we can actually direct teachers towards addressing that crucial gap that's prominent across a lot of students. That would be quite powerful and just like a high leverage moment in a classroom. That's actually some really cool parallels to how we think about our documentation and our documentation bots to this, right? We wanted to look into this for a while. We have chat bots on the website where people can ask questions and yeah, can we use the questions that people are asking to highlight areas where there's just a lot of questions.
 uncertainty or stuff like that. So yeah, maybe we'll be cool to collaborate on some stuff there in the future. For sure. Yeah. Neil Heppernin from Assistments has this interesting tool he's built where basically teachers get like this report on the Nightly homework, which is the most common wrong answer for their class on the homework assigned. And the teachers love that because you know, you can only review so much the next day. And that we can point to.
 Hey, this is the thing that people are getting most wrong. Then you could say, okay, well, what might be the misconception that's triggering that for the most classmates? And if you can get that in that report before they actually teach the next class, then it's up being quite powerful. Well, on this particular thread, whether a perpetual or a West, do you have any additional thoughts either on this question or around additional data calls you might make that might help you personalize or might help you target or might sort of like.
 things that sort of jump out to you on Harrison's questions. Otherwise, I might sort of go through a couple of the questions that are coming to the chat, which have also been great. Yeah, that's a really exciting area, I think. We, something that's different about our project from Joshua's is since working with adult learners, we're kind of assuming minimal engagement from
 the teacher and that this tool will be something that's basically plug and play. And in that context, intelligent tutors would be something that would be incredibly useful. It's about two steps down the development chain before we get to intelligent tutors, I think. But the types of data that we're collecting and it's definitely something that we're keeping in mind is something that's going to be part of.
 of the project. Awesome. And perpetual anything else you would add on just sort of this question around interesting personalization or other calls obviously I saw some of the questions that come in around what about Spanish and you know sort of learners in different contexts especially when it comes to writing. Yeah, I can't speak too much from a product point of view. I think maybe I can speak a little bit.
 a little bit more, I think, on the algorithmic side, I think we've been really excited about the possibilities with recommendation engines and reinforcement learning and building agents that can be intelligent enough to personalize the delivery of content based on the data on user history. So I do echo earlier sentiments there. I did see a question about multilingual abilities with our models. So some of our models do when we have the opportunity to have data that's representative of different languages. One example.
 Well, I'll draw the link in the chat. We had a competition recently that focused on recommending content and learning materials for curriculum design or for course design. And so with that, we were able to source learning materials from a platform called Calibri by the organization Learning Equality, which serves students globally internationally. So whenever there are opportunities to collect data that's representative of different students, as well as different languages, it is an exciting opportunity for us. Can I ask one more question?
 before we jump into some of the user questions. Oh, yes, please. So one, a lot of the talk around product design and product UX has been focused on chat, and how good chat is as like an interface. And so I guess this is maybe a bit more for Josh and Wesley. But as you guys are thinking about designing your applications, I think both of you mentioned some type of chatbot. How do you view chat in the sense of like product UX? Like do you think it's?
 Do you think it's good but not great? Do you think it's the ideal one that you'll set her on? Do you already not like it? Like I'm just curious for your takes on it because I think it's been much discussed. I think it's good as part of a bigger picture. So for example, with the chat bots, we've been just like testing internally. And I think if it's too open in terms of
 But a student can ask it. Again, can just get de-railed really quickly. Like we saw in some of the initial beta testing, like students would ask, like, how is your day? And then the chat about what respond? So that's like sub-optimal. Like we've tried other things like giving specific prompts that they can click on to forward chat bots. That's great. But what I mean in terms of balance, I think, is like, it's like useful as a follow-up to speak.
 specific things that are structured. So for example, with the teaching assistant, I don't think we envision just slapping a chatbot on Depodsy and then having teachers ask whatever they want. We think it's much more powerful instead if we use a language model to generate maybe end of day report. Similar to what Kumar mentioned with assessments and what Neil Huffman is doing, as well as, I think some of the other comments were also talking about after action for teachers.
 Those are really interesting, usually used to use searches. And then if you want to allow teachers to then ask all of questions and make further queries on top of what was already presented in a structured way, I think that's a much more effective solution than just being, than just like lining them do whatever they want. Yeah. Question. Yeah, so piggyback a little bit off of what professional is saying. This isn't a chatbot question, but one one.
 area that reinforcement learning I think would be really useful for us is that we're, we have a single summary evaluation tool. But in different contexts, there may be different, you know, different language domains that it might be more or less appropriate for. So allowing teachers or instructors to spot check the results of the.
 of the scores, you know, and be like, you know, this summary passed, but it obviously shouldn't have passed and give that a thumbs down and just kind of continually iterating the model in that way would be something that would be really useful for us and something on the horizon. Chatbots we haven't really begun to explore yet, but yeah, there's something they are exciting for sure. Oh.
 I mean, the use case that often people cite to me, that's not the chatbot use case, it's some version of a power tool for the instructor, right? It's like co-pilot for the teacher, the sentiment engine that goes to the teacher about who's talking, who's doing this, the feedback tool for the tutor, what are ways to improve the improvement cycle for the instructor, about how they manage the time, whether they focus their teacher moves.
 that they're using and then what's the right way to randomize instructor to student. So like, what's that assignment system? And can you get greater ROI on that? You know, there's been a bunch of great questions in the chat, some of which we will send on to the individual folks in case they might be able to respond to people directly. You know, one that jumped out to me was one that Brewer asked about
 To what extent could you and it builds on hair's impression to what extent could you actually use simulated students to practice to allow instructors to practice in low stake settings different instructional strategies and others. I don't know if anybody among our panelists has looked at the idea that these might actually be good teaching environments in addition to instructional environments.
 a director's student and I'd be curious if anyone's in any thinking or work on that. I think it's good. Yeah, I have not done any thinking on that from the educational perspective, but the only thing I'll add is like I love the idea because I think it's pretty related to some of like the multi-agent stuff that we did in in Langchained where I mean if you want to take it even up another level you could simulate a teacher and a student and then have the teacher like say, oh what could the teacher have done better here? And like
 used in these that is almost like another way of learning. So I think the idea of yeah, having like personalizing and basically accepting like different agents to act in a particular way, whether it's as a student or as a teacher or something like that. Very interesting, but I'm sure Joshua has more relevant things for education to say. Yeah, well, I only started thinking about this last week, because I saw one of the tools competition that Schmidt futures and I think learning agency are helping me running. One of the finalists is
 is actually working on this idea about letting teachers practice, for example, explaining potential misconceptions ahead of time. I think that is one thing that, like, when I was a teacher, I definitely struggled with, because in my mind, I would think, oh, they just, they didn't understand how to subtract with negative integers. I'll be able to explain that, like, without much practice and just do it on the spot. But then when you're actually in front of them, you realize all these other misconceptions that might have gone in the way of them understanding negative integers.
 that I wish I would, if I had a practice run and gotten those questions at a time, I would have been able to structure that lesson in a much more coherent and strategic way. And I think that that is like one powerful way that like large language models can help teachers. Because I think it is like very powerful as a brainstorming partner. Yeah. Awesome. Well, we're running close to time. What I want to do just to help us close out, I think these questions have been awesome. Is invite, Anjali, on the stage. Anjali,
 actually inspired this original GAT in the first place and reaching out to Harrison. And it actually actually leads one of our programs on benefits access. How do we use the technology tools to increase access for Americans as they apply for benefits? But I'm really both welcome them. Thank you for sending this up. And two, what are some of the things that jump out to you in general from this conversation around both the education use cases, but how it might apply to some of the other ones? And then you can also help close this out. Thanks, Mark. And thanks, Harrison, for an all.
 or of our presenters for making this happen. I think the first thing I'll say is that you should always DM people on Twitter, because this is a great way to get things happening. So in the spirit of that, if there are questions or other follow-ups or ideas that have sparked from this conversation, you should continue the conversation ways that our team will drop into the chat. And also, if you are on social media, come chat and come talk about what you are building publicly. A couple of themes that I've been talking about.
 I heard from today that I think are really exciting and motivating. One is, it is such early days. I feel like we say that a lot, but it's such early days for all of this work. And even though we've been doing and so many experts in this field have been building this space for so long, there is in the last six months just so much new technology that has been created, the level of activity that's happened and just the lynching discord alone is wild. And so there's a ton of opportunity to do more and to learn really quickly. So I'm inspired by everyone here.
 who is building and tinkering and learning together. The second thing is I think there are a lot of questions that have come up during this conversation that are super relevant for education and also really, really important for other fields. And what I mean by that is things like how we do summarization or how we query specific bits of information from large documents and translate that into other languages or figure out how we're trying to connect many different languages.
 disparate pieces of complex data all together and build agents that can go off and do things that support critical use cases. Those are important for education and also important for topic areas like climate change or access to government services or legal aid or you name it. And so all of the things that you're building and describing in the chat and in these presentations are really important and also applicable for for other areas as well, because everyone is asking these same questions.
 So in the spirit of that, if you're building in the space, or if you're building something that isn't quite education, but somewhere adjacent, reach out because I think there's a lot of cross-fallination opportunities here. Finally, I'll just offer if there are specific questions that you have or follow-ups or ways that you want to continue to engage or share what you're working on, our team will drop two links into the chat. The first is blank chain discord. The second is the learning engineering Google group, which has thousands of
 people who are also building in this space. And finally, if there are things that you are working on, I'm also happy to chat with anyone at any time and brainstorm with you one on one about things that you're building or questions that you're facing. So my link to my Twitter is in the chat now. Feel free to read down. Thank you. And Harrison, thank you so much for having me and having all of us here and for running this great session for building this community.
 and the work that you're doing in the open. Thank you, Kamar, for joining and thank you, Anjali, for sparking this and thank you, Joshua, and Wesley and perpetual for joining. This was a blast. Awesome. We'll see everybody out there. All right. Bye.
